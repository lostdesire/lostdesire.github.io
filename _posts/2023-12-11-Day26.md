---
title: Day26
date: 2023-12-11 20:00:00 +09:00
categories: [BoostCamp, Week6]
tags: [dl, data, recsys]     # TAG names should always be lowercase
toc: true
toc_sticky: true
use_math: true
---

## 추천 시스템 정의
- 정보 필터링 기술의 일종
- 아마존의 1/3, 넷플릭스의 3/4가 추천시스템을 통해 컨텐츠 소비
- ### Push
	- 사용자가 관심을 가질 만한 정보를 시스템이 밀어내듯이 제공
- ### Pull
	- 사용자의 의도가 명확할 때 사용자의 의도에 맞는 항목을 찾고 추천
- 대부분의 추천 시스템은 Push와 Pull의 중간에 위치

## 추천 시스템 개발 시 고려할 점
### 1. 데이터
- 사용자 / 아이템 관련 정보
- 상호작용 했을 때 발생한 피드백 (CTR, 평점 등)

### 2. Task 설정
- 단기 목표
	- 클릭 수, 특정 기간의 총 수익
- 장기 목표
	- 사이트 소비 시간 증가, 재방문 및 사용자 유지 비율 개선, 구독자 증가
- 일반적으로 최적화 대상은 1가지 (2개 이상을 대상으로 하는 경우도 존재)

### 3. 목적함수 설계
- 설정된 Task에 맞는 목적 함수 설계
- 미래 특정 상황에서 사용자에게 아이템을 제안했을 때 발생하는 <font color="#ffff00">가치</font>를 예측

### 4. 랭킹
- 목적 함수의 기댓값을 최대화할 수 있도록 랭킹 선정 방법 정의
- 연관성, 여러 지표, 비즈니스 규칙 등의 요소를 적절히 조합

## 추천 시스템 성능 평가 방법
- ### 오프라인 평가
	- 수집된 데이터를 train, valid, test 3가지로 분할하여 성능 평가 시 사용
	- #### 데이터 분할 방법
		- ##### Leave One Last
			- 마지막 구매를 test
			- 마지막에서 2번째를 valid
			- 장점
				- 학습 시 많은 데이터 사용 가능
			- 단점
				- 테스트 성능이 전체적인 성능을 반영한다고 보기 어려움
				- 모델이 테스트 데이터 상호작용을 특징으로 학습할 가능성 있음
				- 과거의 데이터가 미래의 정보를 알게되는 <font color="#ffff00">Data Leakage</font>가 발생
		- ##### Temporal User/Global Split
			- 특정 시점을 이용한 분할 전략
			- Temporal User
				- 시간 순서에 따라 일정 비율로 데이터 분할
				- Leave One Last와 유사
				- Data Leakage 발생
			- Temporal Global
				- 유저들의 분할 시점을 고정
				- 학습 및 검증에 사용할 수 있는 상호작용이 적을 수 있음
		- ##### Random Split
			- 시간 순서에 관계 없이 Random하게 분할
			- 사용하기 쉬움
			- 많은 training data
			- Data Leakage 발생
		- ##### User Split
			- 사용자가 겹치지 않게 사용자를 기준으로 분할
			- Cold-Start 대응 가능
			- User-free 모델에서만 사용 가능
			- Data Leakage 발생
		- ##### K-Fold Cross Validation
			- training data를 k개의 fold로 분할하여 한 fold씩 valid data로 사용
		- ##### Time Series Cross Validation
			- 일반적인 CV은 미래를 학습하여 과거를 예측하는 문제가 있음
			- fold 분할 시 시간을 고려 (미래의 데이터 학습 x)
			- 데이터를 늘려가는 방식
			- 데이터를 줄여가는 방식
	- #### 예측 알고리즘 평가 지표
		- ##### 평점 예측 문제
			- RMSE
				- $RMSE = \sqrt{\frac{1}{n}\sum\limits_{i=1}^{N}(y_{i}-\hat{y_{i}})^2}$
			- MAE
				- $MAE = \frac{1}{N}\sum\limits_{i=1}^{N} \left\vert y_{i}-\hat{y_{i}}\right\vert$
		- ##### 랭킹 문제
			- Precision@K
				- 추천한 K개의 아이템 중 유저가 관심있는 아이템의 비율
			- Recall@K
				- 유저가 관심있는 아이템 중 추천한 아이템의 비율
			- <font color="#ff0000">AP@K</font>
				- Precision@1 ~ Precision@K 평균
				- $AP@K = \frac{1}{m}\sum\limits_{i=1}^{K}Precision@i \cdot rel(i)$
				- $m$ : 사용자가 반응한 아이템의 갯수
				- $rel(i)$ : item i와의 relevance score
			- <font color="#ff0000">MAP@K</font>
				- $MAP@K=\frac{1}{\left\vert U\right\vert}\sum\limits_{u=1}^{\left\vert U\right\vert}(AP@K)_{u}$
				- $\left\vert U\right\vert$ : 유저 수
			- ###### Relevance Score
				- CG(Cumulative Gain)
					- $CG_{K}=\sum\limits_{i=1}^{K}rel_{i}$
				- DCG(Discounted CG)
					- $DCG_{K}=\sum\limits_{i=1}^{K}\frac{rel_{i}}{log_2(i+1)}$
				- IDCG(Ideal DCG)
					- $IDCG_{K}=\sum\limits_{i=1}^{K}\frac{rel_{i}^{OPT}}{log_{2}(i+1)}$
				- <font color="#ff0000">NDCG(Normalized DCG)</font>
					- $NDCG_{K}=\frac{DCG}{IDCG}$
				- Hit rate
	- #### 오프라인 평가 지표의 문제점
		- 정확성 개선이 실제 시스템 성능 향상이라고 연관 짓기 어려움
		- 서비스 만족도를 높인다고 보기 어려움
	- #### 특성 평가 지표
		- Coverage
			- 전체 유저/아이템 중 추천 시스템이 추천하는 유저/아이템의 비율
		- Novelty
			- 새로운 아이템 추천
			- 추천하는 인기 항복 수를 줄이기 위해 사용
		- Personalization
			- 개인화된 추천
			- 다른 사용자와 추천된 아이템을 비교
		- Serendipity
			- 의외의 아이템 추천
			- online 평가에서 주로 사용
		- Diversity
			- 얼마나 다양한 아이템이 추천되는지
			- 도메인에 따라 여러 방법으로 측정 가능
				- 카테고리나 장르가 몇가지 추천되는지
				- 판매자, 작가 등이 몇가지 추천되는지
				- 가격 분포의 첨도
				- 추천된 아이템을 임베딩하여 유사도 측정
- ### 온라인 평가
	- 이상적인 테스트
		- 동일 유저에게 A안을 제안하고 시간을 돌려 B안을 제안하는 것
		- 현실에서는 A안과 B안 둘 중 하나만 겪을 수 있음
	- 현실적인 테스트
		- 유저를 두 그룹으로 분할 &rarr; 각각 A안과 B안을 보여준 후 평균 비교
		- 두 그룹의 특성이 모든 면에서 비슷해야함
		- 그룹이 나뉘는 시점도 비슷해야함

## Content Based Filtering
- ### 아이템 특성화
	- Original data &rarr; One-hot encoding &rarr; Embedding
	- 추천 시스템의 경우 아이템의 특성이 왜곡될 수 있어 label encoding은 잘 안함
	- #### TF-IDF
		- 다른 문서에는 많지 않고, 해당 문서에만 자주 등장하는 단어에 높은 값
		- $TF-IDF = freq_{w,d}\times log\frac{N}{n_{W}}$
	- #### Word2Vec
- ### 유사도
	- 특성화된 아이템이 서로 얼마나 비슷한지
	- #### Jaccard
		- 0, 1로 이루어진 binary 데이터로 변환 후, 두 벡터의 교집합과 합집합을 구함
		- $J(A,B)=\frac{\left\vert A\cap B\right\vert}{\left\vert A\cup B\right\vert} = \frac{\left\vert A\cap B\right\vert}{\left\vert A\right\vert+\left\vert B\right\vert-\left\vert A\cup B\right\vert}$
		- 공식이 간단하여 계산 속도가 빠름
	- #### Euclidean
		- n차원으로 주어진 아이템 속성 A,B 벡터 사이의 최단 거리
		- $L_{2}=\sqrt{(A_{1}-B_{1})^2+(A_{2}-B_{2})^2+\cdots+(A_{n}-B_{n})^2}=\sqrt{\sum\limits_{i=1}^{n}(A_{i}-B_{i})^2}$
	- #### Cosine
		- 각도 기반
		- $Similarity=cos(\theta)=\frac{A\cdot B}{\|A\|\cdot\|B\|}=\frac{\sum\limits_{i=1}{n}A_{i}B_{i}}{\sqrt{\sum\limits_{i=1}^{n}(A_{i})^2}\times\sqrt{\sum\limits_{i=1}^{n}(B_{i})^2}}$
		- -1 ~ 1 사이의 값
	- #### Pearson correlation coefficient
		- $Pearson\_sim=\rho_{A,B}=\frac{\sum\limits_{i=1}^{n}(A_{i}-\bar{A})(B_{i}-\bar{B})}{\sqrt{\sum\limits_{i=1}^{n}(A_{i}-\bar{A})^2}\sqrt{\sum\limits{\sum\limits_{i=1}^{n}(B_{i}-\bar{B})^2}}}$
		- -1 ~ 1 사이의 값
		- 선형 상관 관계만 나타내므로 0이 나오면 data의 관계를 알 수 없음

## Memory Based Collaborative Filtering
- 내가 좋아하는 장르, 작가, 출판사의 책
	-> Content Based Filtering
- 나와 비슷한 성향의 사람들이 읽은 책
	-> Collaborative Filtering
- ### Memory Based CF
	- 유저와 아이템의 상호 작용
	- 최적화나 훈련 과정 필요 없음
	- 접근 방식이 쉬움
	- sparse한 데이터의 경우 성능 저하
	- 데이터가 많아지면 계산량의 증가로 인한 확장성의 한계
	- #### User Based CF
		- 새로운 사용자의 경우 정보가 없어 추천이 어려움 (<font color="#ffff00">Cold-Start</font>)
		1. 평점을 기반으로 User-Item matrix 생성
		2. 빈 값을 0으로 채우고, 사용자 사이의 유사도 계산
		3. 유사도를 통한 가중 평균으로 평점 예상
	- #### Item Based CF
		- 시간에 따라 유사도 변화가 적고 User based CF에 비해 계산량이 적음
		- 사용자가 아이템에 feedback한 정보가 많아야 함
		1. 평점을 기준으로 User-Item matrix 생성
		2. 빈 값을 0으로 채우고, 아이템 사이의 유사도 계산
		3. 유사도를 통한 가중 평균으로 평점 예상
- ### Model Based CF
	- Unsupervised Learning
		- Clustering
		- Latent Factor
	- Supervised Learning
		- ML
		- DL
	- 데이터 패턴을 학습하여 추천 가능
	- 유저-아이템 관계의 잠재적 특성 및 패턴 찾기 가능
	- 유저, 아이템 개수가 늘어나도 좋은 성능
	- 학습 이후 서빙 속도 빠름
	- #### Clustering
		- clustering을 다른 추천 방법론과 함께 사용하여 효과적인 추천 수행 가능
			- 군집내 다른 사용자의 선호 아이템 추천
			- clustering 후 CF를 통해 예측 정확도 향상
			- 비슷한 유저 군집 데이터를 추출하여 아이템 선호도를 계산하고 사전 확률로 활용하여 베이지안 방법론 적용 가능
		- 분할 된 데이터의 희소성 문제로 실제 데이터에 적용시 성능 저하
		- 군집 개수 등 파라미터를 직접 설정해야함
		- ##### K-Means Clustering
			- 군집을 k개로 나누는 알고리즘
			- 구형 분포가 아닌 경우 군집화 성능이 저하
			- 아웃라이어에 민감
			1. 랜덤하게 초기 중심점 k개 배치
			2. 각 데이터를 가장 가까운 중심점으로 할당
			3. 모인 데이터 군집의 평균으로 중심점 업데이트
			4. 중심점이 업데이트 되지 않을 때까지 2~3 반복
		- ##### DBSCAN
			- 차원 수가 커질수록 데이터 밀도가 떨어져서 군집 형성이 어려움 (<font color="#ffff00">차원의 저주</font>)
		- ##### GMM(Gaussian Mixture Model)
			- 데이터가 정규성을 만족하지 않는 경우 성능 저하
			- 계산량 많음
		- ##### OPTICS
		- ##### Hierarchical clustering
			- 모든 경우에 대해 반복적으로 유사도를 계산
			- 계산량 많음

## 피어세션
- DL RecSys(2) 리뷰