<h1 id="경사하강법">경사하강법</h1>
<ul>
  <li>미분 / gradient vector</li>
  <li>gradient descent / stochastic gradient descent(minibatch)
    <h1 id="딥러닝">딥러닝</h1>
  </li>
  <li>softmax(classification)</li>
  <li>activation function</li>
  <li>multi-layer perceptron</li>
  <li>backprogpagation(chian rule)</li>
</ul>

<h1 id="확률론">확률론</h1>
<ul>
  <li>discrete(이산형) / continuous(연속형)</li>
  <li>조건부확률</li>
  <li>몬테카를로 샘플링(확률 분포를 모를 때)</li>
</ul>

<h1 id="통계학">통계학</h1>
<ul>
  <li>MLE / Log-likelihood
    <ul>
      <li>쿨백-라이블러 발산(KL Divergence)</li>
    </ul>
  </li>
  <li>베이즈 정리</li>
  <li>precision / recall</li>
</ul>

<h1 id="cnn">CNN</h1>
<ul>
  <li>convolution 연산 / convolution 연산의 역전파</li>
</ul>

<h1 id="rnn">RNN</h1>
<ul>
  <li>시퀀스 데이터</li>
  <li>vanishing gradient -&gt; GRU / LSTM</li>
</ul>

<h1 id="피어세션">피어세션</h1>
<ul>
  <li>1 주차 학습내용 리뷰</li>
  <li>과제 1 &amp; 2 &amp; 3 리뷰</li>
</ul>

<h1 id="마스터클래스">마스터클래스</h1>
<ul>
  <li>임성빈 마스터님의 황금같은 조언</li>
</ul>
