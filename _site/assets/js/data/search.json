[
  
  {
    "title": "Day17",
    "url": "/posts/Day17/",
    "categories": "BoostCamp, Week4",
    "tags": "dl, git, recsys",
    "date": "2023-11-28 20:00:00 +0900",
    





    
    "snippet": "생활코딩 egoing님 git 특강  복구          프로젝트 폴더 전체 복사      커밋 id 복사 해두기      위 두개 대신 “branch”        깃 작업 로그 보기          git reflog        merge          원시 코드 base와 3자 대면                  둘 다 수정 안한 코드 → ...",
    "content": "생활코딩 egoing님 git 특강  복구          프로젝트 폴더 전체 복사      커밋 id 복사 해두기      위 두개 대신 “branch”        깃 작업 로그 보기          git reflog        merge          원시 코드 base와 3자 대면                  둘 다 수정 안한 코드 → 그대로          하나만 수정한 코드 → 수정한거          둘 다 수정한 코드 → 사람이 해결(현재 사항 / 수신 사항 / 모두 수락 / 무시 등)                    피어세션  CNN 리뷰Collaborative Filtering      NBCF                  IBCF                    UBCF                  KNN CF                  KNN Similarity Measure                  MSD(Mean Squared Difference)          Cosine          Pearson          Jaccard 등등                          Rating Prediction                  UBCF                  Absolute Rating                          Average              Weighted Average                                Relative Rating                          Using Deviation                                                  IBCF                  Weighted Average          Using Deviation                          Latent Factor Model          저차원의 행렬로 분해하여 같은 벡터공간으로 만든 후 유사도를 평가            MBCF          모델 학습 / 서빙 빠름      Sparsity / Scalability 개선      Overfitting 방지      Limited Coverage 극복              SVD(Singular Value Decomposition)                  유저 잠재 요인 행렬          잠재 요인 대각 행렬          아이템 잠재 요인 행렬                      Full SVD\\[R = U\\sum\\limits V^T\\]                                Truncated SVD\\[R \\approx \\hat{U} \\sum {_k\\widehat{V^{T}}}= \\hat{R}\\]                    행렬의 Knowledge가 불완전할 때 정의 X          결측치를 모두 채워 Dense Matrix를 만들어서 SVD를 수행하면                          데이터 양 증가, computation 비용 증가                                정확하지 않은 결측치 Imputation은 데이터를 왜곡하고 예층 성능을 저하시킴                          entry가 매우 적을때 SVD 사용하면 과적합                                                  MF(Matrix Factorization)                  User-Item 행렬을 저차원의 User, Item의 latent factor matrix의 곱으로 분해                      관측된 선호도만 모델링에 활용\\[\\begin{aligned}    &amp;R \\approx P \\times Q^{T}= \\hat{R} \\\\    &amp;P \\rightarrow \\left| U \\right| \\times k \\\\    &amp;Q \\rightarrow \\left| I \\right| \\times k  \\end{aligned}\\]                                      ALS(Alternative Least Square)                  User, Item matrix 번갈아가며 업데이트          하나를 고정시키고 다른하나로 least-square          SGD보다 robust하고 병렬처리로 빠른 학습가능                          BPR(Bayesian Personalized Ranking)          item i보다 j를 좋아한다면 더 높은 ranking      관측되지 않은 데이터에 대해                  유저가 아이템에 대해 관심이 없는 것인지          유저가 실제로 관심이 있지만 아직 모르는 것인지 고려                    가정                  관측된 아이템은 관측되지 않은 아이템보다 선호          관측된 아이템끼리는 선호도 추론 불가          관측되지 않은 아이템끼리는 선호도 추론 불가                  \\[\\begin{aligned}    &amp;p(\\theta|_{u}) \\propto p(&gt;_{u}|\\theta)p(\\theta) \\\\    p(\\theta) =\\ 파라미터에\\ 대한&amp;\\ 사전\\ 정보\\ (prior) \\\\    p(&gt;_{u}|\\theta) =\\ 주어진\\ 파라&amp;미터에\\ 대한\\ 유저의\\ 선호\\ 정보의\\ 확률\\ (likelihood) \\\\    p(\\theta|&gt;_{u}) =\\ 주어진\\ 유저&amp;의\\ 선호\\ 정보에\\ 대한\\ 파라미터의\\ 확률\\ (posterior)  \\end{aligned}\\]  "
  },
  
  {
    "title": "Day16",
    "url": "/posts/Day16/",
    "categories": "BoostCamp, Week4",
    "tags": "dl, data, visualization, recsys",
    "date": "2023-11-27 20:00:00 +0900",
    





    
    "snippet": "Data Viz  SeabornRecSys Basic  추천 시스템 개요          Explicit Feedback / Implicit Feedback      Ranking / Prediction        Offline Test          고전적인 통계학 지표      Ranking                  Precision, R...",
    "content": "Data Viz  SeabornRecSys Basic  추천 시스템 개요          Explicit Feedback / Implicit Feedback      Ranking / Prediction        Offline Test          고전적인 통계학 지표      Ranking                  Precision, Recall, MAP, NDCG, Hit Rate                    Prediction                  RMSE, MAE                      Online Test          A/B Test        연관분석  TF-IDF를 활용한 CB(Content-based Recommendation)피어세션  DL Basic의 MLP 리뷰마스터클래스  안수빈 마스터님의 &lt;The Journey of a Data Analyst&gt;"
  },
  
  {
    "title": "Day15",
    "url": "/posts/Day15/",
    "categories": "BoostCamp, Week3",
    "tags": "dl, data, visualization",
    "date": "2023-11-24 20:00:00 +0900",
    





    
    "snippet": "부족한 부분 복습스페셜 피어세션피어세션  주간 회고주간 학습 회고  이번 주는 생긴 의문점들이 많았다.  해결된 것도 있고 안 된 것도 있어서 주말에 좀 더 고민해 봐야겠다.",
    "content": "부족한 부분 복습스페셜 피어세션피어세션  주간 회고주간 학습 회고  이번 주는 생긴 의문점들이 많았다.  해결된 것도 있고 안 된 것도 있어서 주말에 좀 더 고민해 봐야겠다."
  },
  
  {
    "title": "Day14",
    "url": "/posts/Day14/",
    "categories": "BoostCamp, Week3",
    "tags": "dl, data, visualization",
    "date": "2023-11-23 20:00:00 +0900",
    





    
    "snippet": "Data Viz  Text  Color  Facet  More Tips피어세션  심화 과제 1 &amp; 2 리뷰마스터 클래스  최성준 마스터님의 &lt;Learning by Teaching&gt;  가르치는게 머리 속에 가장 오래 남는다",
    "content": "Data Viz  Text  Color  Facet  More Tips피어세션  심화 과제 1 &amp; 2 리뷰마스터 클래스  최성준 마스터님의 &lt;Learning by Teaching&gt;  가르치는게 머리 속에 가장 오래 남는다"
  },
  
  {
    "title": "Matrix Multiply",
    "url": "/posts/Matrix_Multiply/",
    "categories": "BoostCamp, 궁금증",
    "tags": "numpy, matmul",
    "date": "2023-11-22 20:00:00 +0900",
    





    
    "snippet": "다차원에서의 행렬곱  행렬 곱에 대해서 고민하며 시도해보다가 (2, 1, 2, 3, 5)와 (1, 4, 1, 5, 3)가 곱해진다는 것을 알고 혼란에 빠져 버렸다.  이를 해결하기 위해 chat gpt에게 물어본 결과다.BroadcastingNumPy에서는 서로 다른 크기의 배열 간에도 행렬 연산을 수행할 수 있는 기능인 broadcasting이 제공...",
    "content": "다차원에서의 행렬곱  행렬 곱에 대해서 고민하며 시도해보다가 (2, 1, 2, 3, 5)와 (1, 4, 1, 5, 3)가 곱해진다는 것을 알고 혼란에 빠져 버렸다.  이를 해결하기 위해 chat gpt에게 물어본 결과다.BroadcastingNumPy에서는 서로 다른 크기의 배열 간에도 행렬 연산을 수행할 수 있는 기능인 broadcasting이 제공됩니다. Broadcasting은 배열의 차원을 자동으로 조정하여 연산이 가능하도록 만듭니다. 특히, 크기가 1인 차원을 다른 배열의 차원에 맞춰 확장시키는 것이 주요한 원리입니다.다음은 broadcasting이 가능한 경우와 그 원리에 대한 설명입니다:  차원 수가 다른 경우:          broadcasting은 차원 수가 다르더라도 가능합니다. 누락된 차원은 크기가 1로 간주됩니다.        한 배열의 차원 크기가 다른 배열의 해당 차원 크기에 1이 있는 경우:          차원 크기가 1인 차원은 다른 배열의 해당 차원 크기에 맞춰 확장됩니다.      예를 들어, x 배열이 shape이 (2, 1, 2, 1)이고 y 배열이 shape이 (1, 4, 1, 1)인 경우, broadcasting이 가능합니다. 이 경우, x의 두 번째 차원과 y의 두 번째 차원이 크기 1에서 서로 맞춰져 확장됩니다. 따라서 x @ y에서 두 배열 간의 행렬 곱셈이 가능합니다.이런 방식으로 broadcasting이 작동하면서 두 배열 간의 연산이 가능하게 됩니다. NumPy는 이러한 broadcasting을 통해 편리하게 다양한 형태의 배열 간 연산을 수행할 수 있도록 지원합니다.예시두 5차원 배열 A와 B, 그리고 5차원 배열 C에 대한 행렬 곱셈을 예시로 들어보겠습니다. 각 배열의 차원과 크기를 명시하겠습니다.\\[D_{ijkln} = \\sum_{m} A_{ijmkl} \\cdot B_{mklno} \\cdot C_{opqnr}\\]여기서:  ( A )의 shape: (2, 3, 4, 5, 6)  ( B )의 shape: (3, 4, 2, 6, 1)  ( C )의 shape: (4, 2, 3, 1, 5)이제 곱셈을 수행하는 과정을 자세히 설명하겠습니다.과정  D의 첫 번째 차원 (i에 대한 차원):          ( A )의 첫 번째 차원과 ( B )의 첫 번째 차원 중 크기가 더 큰 값으로 결정합니다. 따라서 ( D )의 첫 번째 차원은 3입니다.        D의 두 번째 차원 (j에 대한 차원):          ( B )의 두 번째 차원이 그대로 사용됩니다. 따라서 ( D )의 두 번째 차원은 4입니다.        D의 세 번째 차원 (k에 대한 차원):          ( A )의 세 번째 차원과 ( C )의 첫 번째 차원 중 크기가 더 큰 값으로 결정합니다. 따라서 ( D )의 세 번째 차원은 4입니다.        D의 네 번째 차원 (l에 대한 차원):          ( A )의 네 번째 차원이 그대로 사용됩니다. 따라서 ( D )의 네 번째 차원은 5입니다.        D의 다섯 번째 차원 (n에 대한 차원):          ( C )의 다섯 번째 차원이 그대로 사용됩니다. 따라서 ( D )의 다섯 번째 차원은 5입니다.      결론따라서, ( D )의 shape은 (3, 4, 4, 5, 5)가 됩니다. 이제 ( D )의 각 원소를 구하는데 필요한 곱셈을 수행하여 최종 결과를 얻을 수 있습니다. 이 과정은 각 차원에 대해 대응하는 크기를 고려하여 수행됩니다.  아직도 100퍼센트 이해가 안된것같다…  해당 내용을 코드로 바꿔서 돌려보니 작동하지 않는다. chat gpt 3.5로 돌려서 지 멋대로 내용을 만들어 낸듯하다…제대로 알아내면 올릴 곳…해당 내용에 대해 더 찾아보고 수정해야겠다"
  },
  
  {
    "title": "Day13",
    "url": "/posts/Day13/",
    "categories": "BoostCamp, Week3",
    "tags": "data, visualization",
    "date": "2023-11-22 20:00:00 +0900",
    





    
    "snippet": "Data Viz  시각화의 요소들  Matplotlib  Bar plot  line plot  scatter plot멘토링  RecSys의 validation          offline validation                  top K, precision &amp; recall …                    online valid...",
    "content": "Data Viz  시각화의 요소들  Matplotlib  Bar plot  line plot  scatter plot멘토링  RecSys의 validation          offline validation                  top K, precision &amp; recall …                    online validation                  A/B test                      재노출의 설정          domain에 따라 class에 따라 후처리를 통해 빈도 설정                  우유는 1주일, 옷은 구매하면 x          상황마다 회사마다 다 다르다                    피어세션  기본과제 4 &amp; 5 리뷰"
  },
  
  {
    "title": "행렬 곱에서의 transpose",
    "url": "/posts/matmul_transpose/",
    "categories": "BoostCamp, 궁금증",
    "tags": "dl, transformer, score, T, transpose, permute",
    "date": "2023-11-21 20:00:00 +0900",
    





    
    "snippet": "transformer score 파트에서 생긴 의문들",
    "content": "transformer score 파트에서 생긴 의문들"
  },
  
  {
    "title": "Day12",
    "url": "/posts/Day12/",
    "categories": "BoostCamp, Week3",
    "tags": "dl",
    "date": "2023-11-21 20:00:00 +0900",
    





    
    "snippet": "TransformerGenerative Model과제 5  score 파트에서 생긴 의문          행렬 곱에서의 transpose      깃허브  post link  image upload          use cdn        sitemap 재지정  naver 서치어드바이저 등록",
    "content": "TransformerGenerative Model과제 5  score 파트에서 생긴 의문          행렬 곱에서의 transpose      깃허브  post link  image upload          use cdn        sitemap 재지정  naver 서치어드바이저 등록"
  },
  
  {
    "title": "Transfer Learning에서의 의문",
    "url": "/posts/transfer_learning/",
    "categories": "BoostCamp, 궁금증",
    "tags": "dl, transfer, transfer learning",
    "date": "2023-11-20 20:00:00 +0900",
    





    
    "snippet": "transfer learning의 layer 수정 이유",
    "content": "transfer learning의 layer 수정 이유"
  },
  
  {
    "title": "Day11",
    "url": "/posts/Day11/",
    "categories": "BoostCamp, Week3",
    "tags": "dl",
    "date": "2023-11-20 20:00:00 +0900",
    





    
    "snippet": "DL Historical reviewNN &amp; MLPOptimization  Generalization  Under-fitting vs Over-fitting  Cross Validation  Bias-Variance tradeoff  Bootstrapping  Bagging &amp; BoostingCNNRNN  RNN  LSTM  GRU피어세...",
    "content": "DL Historical reviewNN &amp; MLPOptimization  Generalization  Under-fitting vs Over-fitting  Cross Validation  Bias-Variance tradeoff  Bootstrapping  Bagging &amp; BoostingCNNRNN  RNN  LSTM  GRU피어세션  심화과제1 리뷰  transfer learning에서 layer를 왜 그렇게 수정했는지          transfer learning      과제 1~4  MLP, Optimization, CNN, LSTM"
  },
  
  {
    "title": "Day10",
    "url": "/posts/Day10/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-17 20:00:00 +0900",
    





    
    "snippet": "심화 과제 1  계속 시도 중… 이지만 어렵다스페셜 피어세션  새로운분들을 만나고 관심사에 대해 알아보는 시간피어세션  스페셜 피어세션에 대한 이야기  팀 주간 학습회고주간 학습 회고  이번 주는 생각보다 처음 경험하는 내용도 많았고 배운것도 많은 것 같다.  특히 gather, forward, backward, hook, apply는 처음 배운 내용...",
    "content": "심화 과제 1  계속 시도 중… 이지만 어렵다스페셜 피어세션  새로운분들을 만나고 관심사에 대해 알아보는 시간피어세션  스페셜 피어세션에 대한 이야기  팀 주간 학습회고주간 학습 회고  이번 주는 생각보다 처음 경험하는 내용도 많았고 배운것도 많은 것 같다.  특히 gather, forward, backward, hook, apply는 처음 배운 내용들이라 체득하는데 오래 걸린 것 같다.깃 블로그 업데이트  jeykll theme에서 toc를 써보고 싶은데 계속 안되서 고민중…          Heading을 # 하나가 아니라 ## 부터 toc 정상 적용!      "
  },
  
  {
    "title": "Day9",
    "url": "/posts/Day9/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-16 20:00:00 +0900",
    





    
    "snippet": "Multi GPU  Single Node Single GPU  Single Node Multi GPU  Multi Node Multi GPU  Model Parallel  Data Parallel          Data Parallel      DistributedData Parallel      Hyperparameter Tuning  Hyperp...",
    "content": "Multi GPU  Single Node Single GPU  Single Node Multi GPU  Multi Node Multi GPU  Model Parallel  Data Parallel          Data Parallel      DistributedData Parallel      Hyperparameter Tuning  Hyperparameter Tuning(마지막에 쥐어짤 때)          Grid Layout      Random Layout      Bayesian Layout(최근)        Ray          Multi Node Multi GPU 지원      PyTorch Troubleshooting  OOM(Out of Memory)          Batch Size ↓ → GPU clean → Run      torch.cuda.empty_cache()      del      tensor to list      inference → torch.no_grad()                  backward pass에서의 메모리에서 자유로움                    기본 과제 2 마무리피어세션  기본 과제 2 리뷰마스터클래스  최성철 마스터님의 &lt;ChatGPT시대&gt;  ChatGPT 많이 활용하기"
  },
  
  {
    "title": "Day8",
    "url": "/posts/Day8/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-15 20:00:00 +0900",
    





    
    "snippet": "PyTorch 모델 불러오기  save  checkpoint  transfer learningMonitoring tools  Tensorboard  Wandb기본 과제 2멘토링  논문 읽는 법에 대하여피어세션  기본 과제 1 리뷰두런두런 1회차  변성윤 마스터님 &lt;어쩌다 데이터 사이언티스트&gt;  나는 나 자신을 얼마나 알고 있는가?",
    "content": "PyTorch 모델 불러오기  save  checkpoint  transfer learningMonitoring tools  Tensorboard  Wandb기본 과제 2멘토링  논문 읽는 법에 대하여피어세션  기본 과제 1 리뷰두런두런 1회차  변성윤 마스터님 &lt;어쩌다 데이터 사이언티스트&gt;  나는 나 자신을 얼마나 알고 있는가?"
  },
  
  {
    "title": "Day7",
    "url": "/posts/Day7/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-14 20:00:00 +0900",
    





    
    "snippet": "Pytorch AutoGrad &amp; Optimizer  nn.Module  nn.Parameter  forward  backwardPyTorch Dataset &amp; DataLoader  transforms / Dataset / DataLoader 모듈피어세션  기본 과제 1 (~nn.Module 알쓸신접 전까지) 리뷰기본 과제 1 마무리",
    "content": "Pytorch AutoGrad &amp; Optimizer  nn.Module  nn.Parameter  forward  backwardPyTorch Dataset &amp; DataLoader  transforms / Dataset / DataLoader 모듈피어세션  기본 과제 1 (~nn.Module 알쓸신접 전까지) 리뷰기본 과제 1 마무리"
  },
  
  {
    "title": "Day6",
    "url": "/posts/Day6/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-13 20:00:00 +0900",
    





    
    "snippet": "PyTorch  basic  구조 이해피어세션  심화과제 1 &amp; 2 &amp; 3  기본 과제 1 (nn.Module 알쓸신잡 전까지)기본 과제 1  상당히 오래걸렸지만 새로 알아가는 것이 많았다.",
    "content": "PyTorch  basic  구조 이해피어세션  심화과제 1 &amp; 2 &amp; 3  기본 과제 1 (nn.Module 알쓸신잡 전까지)기본 과제 1  상당히 오래걸렸지만 새로 알아가는 것이 많았다."
  },
  
  {
    "title": "Day5",
    "url": "/posts/Day5/",
    "categories": "BoostCamp, Week1",
    "tags": "ai math",
    "date": "2023-11-10 15:00:00 +0900",
    





    
    "snippet": "심화 과제 1  경사하강법에 대해 좀 더 깊게 알아가는 시간깃블로그 업데이트  아직 미숙한 관계로 더 공부 후에 업데이트 해야겠다…주간 학습 회고  첫주차는 알았던 내용의 복습 &amp; 놓치고 있던 몇몇 부분을 찾는 시간이었다  주말에는 휴식을 가지면서 부족한 부분과 github.io에 대해 좀 더 공부해 봐야겠다",
    "content": "심화 과제 1  경사하강법에 대해 좀 더 깊게 알아가는 시간깃블로그 업데이트  아직 미숙한 관계로 더 공부 후에 업데이트 해야겠다…주간 학습 회고  첫주차는 알았던 내용의 복습 &amp; 놓치고 있던 몇몇 부분을 찾는 시간이었다  주말에는 휴식을 가지면서 부족한 부분과 github.io에 대해 좀 더 공부해 봐야겠다"
  },
  
  {
    "title": "Day4",
    "url": "/posts/Day4/",
    "categories": "BoostCamp, Week1",
    "tags": "ai math",
    "date": "2023-11-09 20:00:00 +0900",
    





    
    "snippet": "경사하강법  미분 / gradient vector  gradient descent / stochastic gradient descent(minibatch)    딥러닝    softmax(classification)  activation function  multi-layer perceptron  backprogpagation(chian rule)확률...",
    "content": "경사하강법  미분 / gradient vector  gradient descent / stochastic gradient descent(minibatch)    딥러닝    softmax(classification)  activation function  multi-layer perceptron  backprogpagation(chian rule)확률론  discrete(이산형) / continuous(연속형)  조건부확률  몬테카를로 샘플링(확률 분포를 모를 때)통계학  MLE / Log-likelihood          쿨백-라이블러 발산(KL Divergence)        베이즈 정리  precision / recallCNN  convolution 연산 / convolution 연산의 역전파RNN  시퀀스 데이터  vanishing gradient -&gt; GRU / LSTM피어세션  1 주차 학습내용 리뷰  과제 1 &amp; 2 &amp; 3 리뷰마스터클래스  임성빈 마스터님의 &lt;AI &amp; Math FAQ&gt;  AI를 배우는 사람에게 황금같은 조언"
  },
  
  {
    "title": "Day3",
    "url": "/posts/Day3/",
    "categories": "BoostCamp, Week1",
    "tags": "python, ai math",
    "date": "2023-11-08 20:00:00 +0900",
    





    
    "snippet": "Python Data Handling  csv / html / xml / json넘파이판다스  series / dataframe  lambda / map / apply  pandas built-in functions  groupby / crosstab / merge / concat  persistence벡터  basic operation  Norm  ...",
    "content": "Python Data Handling  csv / html / xml / json넘파이판다스  series / dataframe  lambda / map / apply  pandas built-in functions  groupby / crosstab / merge / concat  persistence벡터  basic operation  Norm  inner product행렬  basic operation  inner product  inv / pinv          연립방정식 / linear regression      기본 과제 2 &amp; 3피어세션  데이터 전처리 (Filtering &amp; Sorting) 리뷰  새로 오신 팀원분과 자기소개과제 및 퀴즈 리마인드"
  },
  
  {
    "title": "Day2",
    "url": "/posts/Day2/",
    "categories": "BoostCamp, Week1",
    "tags": "python",
    "date": "2023-11-07 20:00:00 +0900",
    





    
    "snippet": "파이썬 데이터 구조파이썬 코드  python style code          ex) split &amp; join, list comprehension…      파이썬 객체지향 프로그래밍  Class          Inheritance / Polymorphism / Visibility        decorator모듈 / 프로젝트  import ...",
    "content": "파이썬 데이터 구조파이썬 코드  python style code          ex) split &amp; join, list comprehension…      파이썬 객체지향 프로그래밍  Class          Inheritance / Polymorphism / Visibility        decorator모듈 / 프로젝트  import / namespace  Virtual Environment파일 / 예외 처리 / 로그  configparser / argparser기본 과제 1피어세션  데이터 전처리 (Getting &amp; Knowing) 리뷰  팀 그라운드 룰 설정데이터 전처리  Filtering &amp; Sorting"
  },
  
  {
    "title": "Day1",
    "url": "/posts/Day1/",
    "categories": "BoostCamp, Week1",
    "tags": "python",
    "date": "2023-11-06 20:00:00 +0900",
    





    
    "snippet": "파이썬 개발환경 설정  vscode / anaconda / terminal 등파이썬 기초 문법  variable / function / conditional &amp; loop / string피어세션  자기소개  Datamanim 사이트 이용 -&gt; 전처리 관련 학습 계획데이터 전처리  Getting &amp; Knowing깃블로그 생성  them...",
    "content": "파이썬 개발환경 설정  vscode / anaconda / terminal 등파이썬 기초 문법  variable / function / conditional &amp; loop / string피어세션  자기소개  Datamanim 사이트 이용 -&gt; 전처리 관련 학습 계획데이터 전처리  Getting &amp; Knowing깃블로그 생성  theme / google search console / google ad sense"
  }
  
]

