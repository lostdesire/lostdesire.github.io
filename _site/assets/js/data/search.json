[
  
  {
    "title": "Day24",
    "url": "/posts/Day24/",
    "categories": "BoostCamp, Week5",
    "tags": "dl, data, recsys",
    "date": "2023-12-07 20:00:00 +0900",
    





    
    "snippet": "MAB(Multi-Armed Bandit)  MAB의 정책          모든 슬롯머신을 동일한 횟수로 당김                  높은 reward 불가능                    일정 횟수 후 제일 높은 확률의 슬롯머신만 당김                  동일한 슬롯만 계속 당김                      Explor...",
    "content": "MAB(Multi-Armed Bandit)  MAB의 정책          모든 슬롯머신을 동일한 횟수로 당김                  높은 reward 불가능                    일정 횟수 후 제일 높은 확률의 슬롯머신만 당김                  동일한 슬롯만 계속 당김                      Exploration          더 많은 정보를 얻기 위해 새로운 arm을 선택하는 것        Exploitation          경험 / 관측을 토대로 가장 좋은 arm을 선택하는 것        \\[q_{*}(a) \\doteq \\mathbb{E}[R_{t} | A_{t} = a]\\]          $A_{t}$ : action      $R_{t}$ : reward      $q_{*}(a)$ : 액션 a에 따른 reward의 실제 기대값        $q_{*}(a)$에 대한 시간 t에서의 추정치 $Q_{t}(a)$를 최대한 정밀하게 구하는 것이 목표  greedy action 선택 → exploitation  다른 action 선택 → exploration      Greedy Algorithm          Simple Average Method      \\[Q_{t}(a) \\doteq \\frac{sum\\ of\\ rewards\\ when\\ a\\ taken\\ prior\\ to\\ t}{number\\ of\\ times\\ a\\ taken\\ prior\\ to\\ t} = \\frac{\\sum_{i=1}^{t-1}R_{i}\\cdot 1_{A_{i}=a}}{\\sum_{i=1}^{t-1}1_{A_{i}=a}}\\]            실제 기대값 $q_{*}(a)$의 가장 간단한 추정 방식으로 표본 평균을 사용      평균 리워드가 최대인 action을 선택하는 것 → Greedy                  처음 선택되는 action과 reward에 크게 영향을 받음(exploration이 부족)                          Epsilon-Greedy Algorithm          exploration이 부족한 greedy algorithm을 수정      ​일정한 확률에 의해 랜덤으로 슬롯머신을 선택      \\[A_{t} \\doteq \\underset{a}{argmax}\\begin{bmatrix}Q_{t}(a) + c\\sqrt\\frac{\\ln t}{N_{t}(a)}\\end{bmatrix}\\]                  $Q_{t}(a)$ : action a에 대한 reward의 추정치 (simple average)          $N_{t}(a)$ : action a를 선택한 횟수          c : exploration을 조정하는 하이퍼파라미터                      ​개별 아이템 ← 개별 action  ​추천 방식 ← MAB policy  ​클릭 여부 ← reward      유저 추천          ​클러스터링을 통해 비슷한 유저끼리 그룹화      필요 Bandit 개수 = 유저 클러스터 개수 x 후보 아이템 개수            유사 아이템 추천          주어진 아이템과 유사한 후보 아이템 리스트를 생성      필요 Bandit 개수 = 아이템 개수 x 후보 아이템 개수            Thompson Sampling          주어진 k개의 action에 해당하는 확률분포를 구하는 문제      베타 분포                  두 개의 양의 변수로 표현 가능한 확률 분포          \\[Beta(x|\\alpha, \\beta) = \\frac{1}{B(\\alpha, \\beta)}x^{\\alpha-1}(1-x)^{\\beta-1}\\]                    $B(\\alpha, \\beta)$는 $\\alpha, \\beta$에 의해 정해지는 베타 함수          배너를 보고 클릭한 횟수 $\\alpha$          배너를 보고 클릭하지 않은 횟수 $\\beta$          배너를 클릭할 확률 ~ $Beta(\\alpha+1, \\beta+1)$          초기에는 랜덤 노출 → 베타 분포에서 샘플링하여 노출                          LinUCB          Contextual Bandit      유저 context 정보에 따라 동일한 action이더라도 다른 reward를 가짐 (개인화 추천)      \\[A_{t} \\doteq \\underset{a}{argmax}\\begin{bmatrix}x_{t,a}^{T}\\theta_{a}^{*} + \\alpha\\sqrt{x_{t,a}^{T}A_{a}^{-1}X_{t,a}}\\end{bmatrix} \\qquad where A_{a} = D_{a}^{T}D_{a}+I_{d}\\]                  $x_{t,a}$ : d-차원 컨텍스트 벡터          $\\theta_{a}^{*}$ : action a에 대한 d-차원 학습 파라미터          $D_{a}$ : m개의 컨텍스트 벡터로 구성된 $m\\times d$ 행렬                    피어세션  Item2Vec &amp; ANN 리뷰마스터클래스  이준원 마스터님의 &lt;ML Career 만들기 (Feat. AD-Tech)&gt;  이직 : 필수 조건 / 꼭 만족하지 않아도 되는 조건 고려  중요한 것 : 1. 개발 능력, 2. ML/DL 지식 및 이해도, 3) 커뮤니케이션 → 문제해결력  주니어 때는 하나의 도메인과 직무에서 깊이를 쌓는 것이 좋다."
  },
  
  {
    "title": "Day23",
    "url": "/posts/Day23/",
    "categories": "BoostCamp, Week5",
    "tags": "dl, data, recsys, wide&deep, deepfm, din, bst",
    "date": "2023-12-06 20:00:00 +0900",
    





    
    "snippet": "Wide &amp; Deep      Memorization          같이 자주 등장하는 item / feature를 과거로부터 학습      LR            Generalization          드물거나 전혀 발생한 적 없는 item / feature를 기존 관계로부터 발견      FM, DNN        두 특성을 가지는 ...",
    "content": "Wide &amp; Deep      Memorization          같이 자주 등장하는 item / feature를 과거로부터 학습      LR            Generalization          드물거나 전혀 발생한 적 없는 item / feature를 기존 관계로부터 발견      FM, DNN        두 특성을 가지는 구조를 결합      The Wide Component          Generalized Linear Model                  \\[y = w^Tx + b\\]                              Cross-Product Transformation                  \\[\\phi_{k}(x) = \\prod_{i=1}^{d}x_{i}^{c_{ki}} \\qquad c_{ki} \\in \\{0, 1\\}\\]                                    The Deep Component          Feed-Forward Neural Network                  3 layer (ReLU)          연속형 변수 → 그대로 사용          범주형 변수 → feature embedding 후 사용                      \\[P(Y = 1|x) = \\sigma(W_{wide}^{T}[x, \\phi(x)] + W_{deep}^{T}a^{(lf)} + b)\\]    Wide model은 offline / Deep model은 online에서 좋은 현상을 보이므로 두 모델을 결합하여 모두 좋은 성능DeepFM  Wide &amp; Deep model의 wide component는 feature engineering(Cross-Product Transformation)이 필요하다는 단점이 있음  wide component로 FM을 사용하여 deep component의 dense embedding 입력값을 공유  DeepFM = FM + DNN  \\(\\hat y = sigmoid(y_{FM}+y_{DNN})\\)DIN(Deep Interest Network)  다양한 관심사를 반영하기 위해 나온 모델          Embedding Layer              Local Activation Layer                  후보군이 되는 광고를 기존에 본 광고들의 연관성을 계산하여 가중치로 표현                    Fully-connected Layer      BST(Behavior Sequence Transformer)  CTR 예측과 NLP 번역 데이터 간의 공통점                  대부분 sparse feature            low/high-order feature interaction 모두 존재 (비선형적 관계)        Transformer의 encoder만 사용  vs DIN          local activation layer → transformer layer      user behavior feature → user behavior sequence        vs Transformer                  dropout, leakyReLU        추가                    layer 1~4개만        사용 (best는 1개)                    Custom Positional Encoding                  \\(pos(v_{i}) = t(v_{t}) - t(v_{i})\\)                    피어세션  CF 리뷰"
  },
  
  {
    "title": "Macbook Setting",
    "url": "/posts/Macbook_Setting/",
    "categories": "Mac, Setting",
    "tags": "mac",
    "date": "2023-12-05 20:00:00 +0900",
    





    
    "snippet": "언젠가 맥북을 다시 설정하는 날이 있을 때 한번에 해결하기 위한 포스트Karabiner  마우스를 사용할 시 인터넷 환경에서 뒤로가기 앞으로가기를 활성화 시키기          Karabiner를 설치 후 여러 권한들 허용      Karabiner-Elements → Complex Modifications → Add rule      하단의 Impo...",
    "content": "언젠가 맥북을 다시 설정하는 날이 있을 때 한번에 해결하기 위한 포스트Karabiner  마우스를 사용할 시 인터넷 환경에서 뒤로가기 앞으로가기를 활성화 시키기          Karabiner를 설치 후 여러 권한들 허용      Karabiner-Elements → Complex Modifications → Add rule      하단의 Import → Change mouse buttons (rev 2) Import      Change button4,5 to back,forward (rev 1) Enable      Devices → Mouse의 Modifiy events 활성화      Homebrew  터미널에서 homebrew 설치하기    /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"        버전 확인    brew --version        오류 발생시      $ brew --version  zsh: command not found: brew  # zshrc에 homebrew path 추가  $ echo 'export PATH=/opt/homebrew/bin:$PATH' &gt;&gt; ~/.zshrc  # zshrc 반영  $ source ~/.zshrc      Iterm2brew install --cask iterm2  Appearance → Theme - Minimal  Profiles → Session → Status bar enabled (세부설정으로 여러가지 설정가능)  Profiles → Colors → Color Presets로 다운 받은 iterm2 color 적용  iCloud 접근          /Users/UserName/Library/Mobile\\ Documents/com~apple~CloudDocs      Oh-my-zshsh -c \"$(curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh)\"  p10k    git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k        테마 적용          vi ~/.zshrc → ZSH_THEME=”ZSH_THEME=”powerlevel10k/powerlevel10k”      재실행      Meslo Nerd Font 설치 후 재실행      아이콘이 다 보이면 y      세부 테마 설정      3 → 1 → 1 → 3 → 1 → 1 → 1 → 1 → 2 → 1 → n → 1 → y        추천 플러그인batbrew install batfdbrew install fdauto suggestionsgit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestionssyntax highlightinggit clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting$vi ~/.zshrcsource ~/.oh-my-zsh/custom/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zshautojumpbrew install autojumpghbrew install ghVSCode  homebrew를 통해 vscode 설치하기    brew install --cask visual-studio-code        –cask는 GUI 응용프로그램 설치할 때 (~/Applications에 설치됨)  깔면 좋은 익스텐션          Korean Language Pack for Visual Studio Code (대부분 기본 설치)      Git Graph      Jupyter / Jupyter PowerToys      Material Icon Theme      Prettier        terminal font family          MesloLGS NF      anaconda3  homebrew를 통해 anaconda 설치하기    brew install --cask anaconda        버전 확인    conda -V        오류 발생시    $ echo 'export PATH=/opt/homebrew/anaconda3/bin:$PATH' &gt;&gt; ~/.zshrc$ source ~/.zshrc      Ruby &amp; Jekyll  github blog 로컬 테스트를 위한 jekyll 설치      brew install rbenv ruby-build  rbenv install -l  rbenv install 3.2.2 (2023-12-06 기준)  $ vi ~/.zshrc  [[ -d ~/.rbenv  ]] &amp;&amp; \\\texport PATH=${HOME}/.rbenv/bin:${PATH} &amp;&amp; \\\teval \"$(rbenv init -)\"  rbenv global 3.2.2  bundle install  gem install jekyll bundler      "
  },
  
  {
    "title": "Day22",
    "url": "/posts/Day22/",
    "categories": "BoostCamp, Week5",
    "tags": "dl, data, recsys, git",
    "date": "2023-12-05 20:00:00 +0900",
    





    
    "snippet": "생활코딩 egoing님 2차 특강      1차 특강 복습          git add      git commit                  –amend -m “example”          head가 가리키는 commit message 바뀜 (commit id도 달라짐)                    git checkout      gi...",
    "content": "생활코딩 egoing님 2차 특강      1차 특강 복습          git add      git commit                  –amend -m “example”          head가 가리키는 commit message 바뀜 (commit id도 달라짐)                    git checkout      git branch      git reset (–hard)                  checkout은 head를 reset은 branch를 변경                    git merge                  rebase, revert, cherry-pick은 3-way merge에 의해 conflict 발생                          git rebase          base를 변경하여 history가 마치 한 줄인 것처럼      이미 공개 저장소에 Push 한 커밋을 Rebase 하지 마라      타임라인의 축소 branch의 commit 순서 합치고 main의 commit 순서 합치고      git rebase main exp                  main의 base를 exp로 간주          main → exp                          main의 원래 base에서 첫 commit까지의 변화를 exp에 반영              main의 이후 commit을 새로 생긴 것과 결합                                exp1 → exp2 → exp2 &amp; main1 &amp; base (main1) → rebase1 &amp; main2 &amp; main1 (main2)                          git cherry-pick          다른 branch의 특정 commit 하나의 변경사항을 가져오는 것      main이 exp1에서 exp2의 변경사항을 가져오는 것      exp2 &amp; main2 &amp; exp1      git cherry-pick –abort                  cherry-pick을 되돌리고 싶으면 –abort를 사용                          git pull          git에 있는 remote repository 변경사항 local에 반영      fetch + merge      내용이 다를시 merge commit 자동 생성            git clone          remote repository 복사      init + remote add REPO_URL + pull      "
  },
  
  {
    "title": "Day21",
    "url": "/posts/Day21/",
    "categories": "BoostCamp, Week5",
    "tags": "dl, data, recsys, fm, ffm, gbm",
    "date": "2023-12-04 20:00:00 +0900",
    





    
    "snippet": "DL RecSys  GNN          Relation, Interaction에 적합      Non-Euclidean Space의 표현, 학습 가능 (sns, 분자)        NGCF          유저와 아이템 임베딩      상호작용 모델링                                            임베딩 레이어    ...",
    "content": "DL RecSys  GNN          Relation, Interaction에 적합      Non-Euclidean Space의 표현, 학습 가능 (sns, 분자)        NGCF          유저와 아이템 임베딩      상호작용 모델링                                            임베딩 레이어                                                          임베딩 전파 레이어                                                          유저-아이템 선호도 예측 레이어                                          L = 3~4일 때 가장 좋은 성능      MF보다 빠르게 수렴하고 recall이 높음        LightGCN          이웃노드의 임베딩을 가중합      concat 하지 않고 가중합으로 대체하여 연산량 감소      training loss와 추천 성능 모두 NGCF보다 뛰어남        GRU4Rec          고객이 지금 좋아하는 것 찾기      세션을 GRU 레이어에 입력하여 다음에 올 확률이 높은 아이템 추천      길이가 짧은 세션과 긴 세션을 묶어 병렬적으로 구성하여 mini-batch 학습      아이템을 negative sampling하여 subset만으로 loss 계산      상호작용하지 않은 아이템은 몰랐거나 관심이 없는 것      Context-aware Recommendation  MF 기반 CF는 상호작용 정보가 부족할 때(cold start)에 대한 대처가 어려움  상호작용 정보 뿐만 아니라 맥락 정보도 함께 반영  CTR 예측 등에 사용  sparse feature에 매우 좋은 성능FM  Factorization Machine  \\[\\hat{y}(x) = w_{0} + \\sum_{i=1}^{n}w_{i}x_{i} + \\sum_{i=1}^{n}\\sum_{j=i+1}^{n} &lt;v_{i}, v_{j}&gt;x_{i}x_{j}\\]    MF와 다르게 범용적인 지도 학습 모델  유저, 아이템 id외에 다른 정보도 모델의 feature로 사용 가능FFM  Field-aware FM  \\[\\hat{y}(x) = w_{0} + \\sum_{i=1}^{n}w_{i}x_{i} + \\sum_{i=1}^{n}\\sum_{j=i+1}^{n} &lt;v_{i, f_j}, v_{j, f_i}&gt;x_{i}x_{j}\\]    하나의 변수에 대해 필드 개수(f)와 factorization 차원(k)의 곱(fk)만큼의 파라미터 학습 (FM은 k 파라미터)GBM  Gradient Boosting Machine  하이퍼파라미터에 비교적 민감하지 않은 robust한 모델  이전 단계 weak learner까지의 잔차(residual)을 계산하여 다음 weak learner를 학습함  회귀문제          residual        분류문제          log(odds)        장점          random forest보다 나은 성능        단점          느린 학습 속도      과적합 문제        GBM의 단점을 해결하기 위한 모델 / 라이브러리          XGBoost                  병렬처리 / 근사 알고리즘 사용으로 학습 속도 개선                    LightGBM                  병렬처리 없이도 빠르게 학습                    CatBoost                  범주형 변수에 효과적                    "
  },
  
  {
    "title": "Day20",
    "url": "/posts/Day20/",
    "categories": "BoostCamp, Week4",
    "tags": "dl, data, recsys, visualization",
    "date": "2023-12-01 20:00:00 +0900",
    





    
    "snippet": "Item2Vec, ANN, DL RecSys 정리  Day18스페셜 피어세션피어세션  Generative Model 리뷰주간회고  이번주부터 처음으로 RecSys에 관련된 내용을 학습했다  내용들이 전부 처음보는 거라 주말에 진짜 복습을 좀 해서 정리를 해야겠다",
    "content": "Item2Vec, ANN, DL RecSys 정리  Day18스페셜 피어세션피어세션  Generative Model 리뷰주간회고  이번주부터 처음으로 RecSys에 관련된 내용을 학습했다  내용들이 전부 처음보는 거라 주말에 진짜 복습을 좀 해서 정리를 해야겠다"
  },
  
  {
    "title": "Day19",
    "url": "/posts/Day19/",
    "categories": "BoostCamp, Week4",
    "tags": "dl, data, recsys, visualization, plotly, bokeh, altair",
    "date": "2023-11-30 20:00:00 +0900",
    





    
    "snippet": "기본 과제 2 마무리  It works…? Why?Data Viz  Polar Coordinate  Pie Chart  시각화 라이브러리  Interactive Visualization          Plotly      Plotly Express      Bokeh      Altair        Custom Matplotlib Theme  Im...",
    "content": "기본 과제 2 마무리  It works…? Why?Data Viz  Polar Coordinate  Pie Chart  시각화 라이브러리  Interactive Visualization          Plotly      Plotly Express      Bokeh      Altair        Custom Matplotlib Theme  Image &amp; Text Visualization Techniques피어세션  transformer 리뷰내일은 18일차 정리 안된거 정리하기"
  },
  
  {
    "title": "Day18",
    "url": "/posts/Day18/",
    "categories": "BoostCamp, Week4",
    "tags": "dl, git, recsys, item2vec, ann",
    "date": "2023-11-29 20:00:00 +0900",
    





    
    "snippet": "기본 과제 1  Matrix Factorization  Alternative Least Squares피어세션  RNN, LSTM 리뷰Item2Vec  CBOW(Continuous Bag of Words)          앞 뒤로 각각 n개의 단어 슬라이딩 윈도우 형태로        SG(Skip Gram)          CBOW의 입력층과 출력층이 ...",
    "content": "기본 과제 1  Matrix Factorization  Alternative Least Squares피어세션  RNN, LSTM 리뷰Item2Vec  CBOW(Continuous Bag of Words)          앞 뒤로 각각 n개의 단어 슬라이딩 윈도우 형태로        SG(Skip Gram)          CBOW의 입력층과 출력층이 바뀐 모델      CBOW보다 성능이 좋다고 알려져 있음        SGNS(Skip Gram with Negative Sampling)          Item2Vec에서 사용하는 학습 방법      SG의 입력과 레이블을 모두 입력값으로      레이블을 이진 분류(주변 단어는 1, 그 외는 0)      0의 개수는 Hyperparameter(학습데이터가 적은 경우 5~20, 큰 경우 2~5)      중심 단어 layer, 주변 단어 layer 2개의 embedding layer 존재        Item2Vec          공간적 / 시간적 정보를 무시      동일한 아이템 집합 내 아이템 쌍들은 모두 SGNS의 Positive Sample이 됨      Skip-Gram이 n개의 단어를 사용한 것과 달리 모든 단어 쌍을 사용      ANN  Approximate Nearest Neighbor  Brute Force KNN          정확도는 100프로지만 시간이 오래걸림        ANNOY          spotify에서 개발한 tree based ANN      parameter를 통해 accuarcy ↔ speed trade-off 조정 가능 (num_tree, search_k)                                            임의의 두 점 선택 → 두 점 사이의 hyperplane으로 vector space 분리                                                          subspace의 점들을 node로 하여 binary tree 생성 or 갱신                                                          subspace 내의 점들이 K개 이상이라면 1~2 반복                                          문제점                  가장 근접한 점이 tree의 다른 node에 있을 경우 해당 점은 후보 subset에 포함되지 못함                    해결 방안                  priority queue 사용하여 가까운 다른 node 탐색          binary tree를 여러 개 생성하여 병렬적으로 탐색                      HNSW(Hierarchical Navigable Small World Graphs)          벡터를 그래프의 node로 표현하고 인접한 벡터를 edge로 연결      nmslib, faiss 등                                            최상위 layer에서 임의의 노드에서 시작                                                          현재 layer에서 타겟 노드와 가장 가까운 노드로 이동                                                          현재 layer에서 더 가까워 질 수 없으면 하위 layer로 이동                                                          타켓 노드에 도착할 때 까지 2~3 반복                                                          2~4를 진행했을 때 방문했던 노드들만 후보로 하여 NN 탐색                                            IVF(Inverted File Index)          탐색해야 하는 cluster 개수를 증가시킬수록 accuracy ↔ speed trade-off 발생                                            주어진 vector를 clustering을 통해 n개의 cluster로 나눠서 저장                                                          vector의 index를 cluster별 inverted list로 저장                                                          query vector에 대해서 해당 cluster를 찾고 invert list 안에 있는 vector들에 대해 탐색                                            Product Quantization - Compression          두 vector의 유사도를 구하는 연산이 거의 요구되지 않음      centroid 사이의 유사도 이용      PQ와 IVF를 동시에 사용해서 더 빠르고 효율적인 ANN 수행 (faiss)                                            기존 vector를 n개의 sub-vector로 나눔                                                          각 sub-vecotr 군에 대해 k-mens clustering을 통해 centroid를 구함                                                          기존의 모든 vector를 n개의 centroid로 압축해서 표현                                          DL RecSys  추천 시스템에서 딥러닝을 사용하는 이유          Nonlinear Transformation      Representation Learning      Sequence Modeling      Flexibility        NCF(Neural Collaborative Filtering)          MF의 한계 ← 선형 조합      user / item latent vector → MLP        YouTube Recommendation                            Candidate Generation                          High Recall이 목표              Top N 추천 아이템 생성                                                            Ranking                          유저, 비디오 feature를 좀 더 풍부하게 사용              logistic 회귀 사용              시청 시간을 가중치로                                            AutoRec          AE를 CF에 적용      Rating Vector를 입력과 출력으로 Encoder &amp; Decoder Reconstruction 수행      non-linear activation function을 사용하므로 더 복잡한 interaction 표현 가능      아이템 / 유저 둘 중 한 번에 하나에 대한 임베딩만을 진행        CDAE(Collaborative Denoising Auto-Encoder)          AutoRec이 Rating Predicion이었다면 CDAE는 Top-N 추천      유저-아이템 상호작용 정보를 0 or 1로 바꿔서 학습데이터로 사용      기본 과제 2  Neural Collaborative Filtering  AutoRec"
  },
  
  {
    "title": "Day17",
    "url": "/posts/Day17/",
    "categories": "BoostCamp, Week4",
    "tags": "dl, git, recsys, cf, nbcf, knn cf, latent, svd, mf, als, bpr",
    "date": "2023-11-28 20:00:00 +0900",
    





    
    "snippet": "생활코딩 egoing님 git 특강  복구          프로젝트 폴더 전체 복사      커밋 id 복사 해두기      위 두개 대신 “branch”        깃 작업 로그 보기          git reflog        merge          원시 코드 base와 3자 대면                  둘 다 수정 안한 코드 → ...",
    "content": "생활코딩 egoing님 git 특강  복구          프로젝트 폴더 전체 복사      커밋 id 복사 해두기      위 두개 대신 “branch”        깃 작업 로그 보기          git reflog        merge          원시 코드 base와 3자 대면                  둘 다 수정 안한 코드 → 그대로          하나만 수정한 코드 → 수정한거          둘 다 수정한 코드 → 사람이 해결(현재 사항 / 수신 사항 / 모두 수락 / 무시 등)                    피어세션  CNN 리뷰Collaborative Filtering      NBCF                  IBCF                    UBCF                  KNN CF                  KNN Similarity Measure                  MSD(Mean Squared Difference)          Cosine          Pearson          Jaccard 등등                          Rating Prediction                  UBCF                  Absolute Rating                          Average              Weighted Average                                Relative Rating                          Using Deviation                                                  IBCF                  Weighted Average          Using Deviation                          Latent Factor Model          저차원의 행렬로 분해하여 같은 벡터공간으로 만든 후 유사도를 평가            MBCF          모델 학습 / 서빙 빠름      Sparsity / Scalability 개선      Overfitting 방지      Limited Coverage 극복              SVD(Singular Value Decomposition)                  유저 잠재 요인 행렬          잠재 요인 대각 행렬          아이템 잠재 요인 행렬                      Full SVD\\[R = U\\sum\\limits V^T\\]                                Truncated SVD\\[R \\approx \\hat{U} \\sum {_k\\widehat{V^{T}}}= \\hat{R}\\]                    행렬의 Knowledge가 불완전할 때 정의 X          결측치를 모두 채워 Dense Matrix를 만들어서 SVD를 수행하면                          데이터 양 증가, computation 비용 증가                                정확하지 않은 결측치 Imputation은 데이터를 왜곡하고 예층 성능을 저하시킴                          entry가 매우 적을때 SVD 사용하면 과적합                                                  MF(Matrix Factorization)                  User-Item 행렬을 저차원의 User, Item의 latent factor matrix의 곱으로 분해                      관측된 선호도만 모델링에 활용\\[\\begin{aligned}    &amp;R \\approx P \\times Q^{T}= \\hat{R} \\\\    &amp;P \\rightarrow \\left| U \\right| \\times k \\\\    &amp;Q \\rightarrow \\left| I \\right| \\times k  \\end{aligned}\\]                                      ALS(Alternative Least Square)                  User, Item matrix 번갈아가며 업데이트          하나를 고정시키고 다른하나로 least-square          SGD보다 robust하고 병렬처리로 빠른 학습가능                          BPR(Bayesian Personalized Ranking)          item i보다 j를 좋아한다면 더 높은 ranking      관측되지 않은 데이터에 대해                  유저가 아이템에 대해 관심이 없는 것인지          유저가 실제로 관심이 있지만 아직 모르는 것인지 고려                    가정                  관측된 아이템은 관측되지 않은 아이템보다 선호          관측된 아이템끼리는 선호도 추론 불가          관측되지 않은 아이템끼리는 선호도 추론 불가                  \\[\\begin{aligned}    &amp;p(\\theta|_{u}) \\propto p(&gt;_{u}|\\theta)p(\\theta) \\\\    p(\\theta) =\\ 파라미터에\\ 대한&amp;\\ 사전\\ 정보\\ (prior) \\\\    p(&gt;_{u}|\\theta) =\\ 주어진\\ 파라&amp;미터에\\ 대한\\ 유저의\\ 선호\\ 정보의\\ 확률\\ (likelihood) \\\\    p(\\theta|&gt;_{u}) =\\ 주어진\\ 유저&amp;의\\ 선호\\ 정보에\\ 대한\\ 파라미터의\\ 확률\\ (posterior)  \\end{aligned}\\]  "
  },
  
  {
    "title": "Day16",
    "url": "/posts/Day16/",
    "categories": "BoostCamp, Week4",
    "tags": "dl, data, visualization, recsys",
    "date": "2023-11-27 20:00:00 +0900",
    





    
    "snippet": "Data Viz  SeabornRecSys Basic  추천 시스템 개요          Explicit Feedback / Implicit Feedback      Ranking / Prediction        Offline Test          고전적인 통계학 지표      Ranking                  Precision, R...",
    "content": "Data Viz  SeabornRecSys Basic  추천 시스템 개요          Explicit Feedback / Implicit Feedback      Ranking / Prediction        Offline Test          고전적인 통계학 지표      Ranking                  Precision, Recall, MAP, NDCG, Hit Rate                    Prediction                  RMSE, MAE                      Online Test          A/B Test        연관분석  TF-IDF를 활용한 CB(Content-based Recommendation)피어세션  DL Basic의 MLP 리뷰마스터클래스  안수빈 마스터님의 &lt;The Journey of a Data Analyst&gt;"
  },
  
  {
    "title": "Day15",
    "url": "/posts/Day15/",
    "categories": "BoostCamp, Week3",
    "tags": "dl, data, visualization",
    "date": "2023-11-24 20:00:00 +0900",
    





    
    "snippet": "부족한 부분 복습스페셜 피어세션피어세션  주간 회고주간 학습 회고  이번 주는 생긴 의문점들이 많았다.  해결된 것도 있고 안 된 것도 있어서 주말에 좀 더 고민해 봐야겠다.",
    "content": "부족한 부분 복습스페셜 피어세션피어세션  주간 회고주간 학습 회고  이번 주는 생긴 의문점들이 많았다.  해결된 것도 있고 안 된 것도 있어서 주말에 좀 더 고민해 봐야겠다."
  },
  
  {
    "title": "Day14",
    "url": "/posts/Day14/",
    "categories": "BoostCamp, Week3",
    "tags": "dl, data, visualization",
    "date": "2023-11-23 20:00:00 +0900",
    





    
    "snippet": "Data Viz  Text  Color  Facet  More Tips피어세션  심화 과제 1 &amp; 2 리뷰마스터 클래스  최성준 마스터님의 &lt;Learning by Teaching&gt;  가르치는게 머리 속에 가장 오래 남는다",
    "content": "Data Viz  Text  Color  Facet  More Tips피어세션  심화 과제 1 &amp; 2 리뷰마스터 클래스  최성준 마스터님의 &lt;Learning by Teaching&gt;  가르치는게 머리 속에 가장 오래 남는다"
  },
  
  {
    "title": "Matrix Multiply",
    "url": "/posts/Matrix_Multiply/",
    "categories": "BoostCamp, 궁금증",
    "tags": "numpy, matmul",
    "date": "2023-11-22 20:00:00 +0900",
    





    
    "snippet": "다차원에서의 행렬곱  행렬 곱에 대해서 고민하며 시도해보다가 (2, 1, 2, 3, 5)와 (1, 4, 1, 5, 3)가 곱해진다는 것을 알고 혼란에 빠져 버렸다.  이를 해결하기 위해 chat gpt에게 물어본 결과다.BroadcastingNumPy에서는 서로 다른 크기의 배열 간에도 행렬 연산을 수행할 수 있는 기능인 broadcasting이 제공...",
    "content": "다차원에서의 행렬곱  행렬 곱에 대해서 고민하며 시도해보다가 (2, 1, 2, 3, 5)와 (1, 4, 1, 5, 3)가 곱해진다는 것을 알고 혼란에 빠져 버렸다.  이를 해결하기 위해 chat gpt에게 물어본 결과다.BroadcastingNumPy에서는 서로 다른 크기의 배열 간에도 행렬 연산을 수행할 수 있는 기능인 broadcasting이 제공됩니다. Broadcasting은 배열의 차원을 자동으로 조정하여 연산이 가능하도록 만듭니다. 특히, 크기가 1인 차원을 다른 배열의 차원에 맞춰 확장시키는 것이 주요한 원리입니다.다음은 broadcasting이 가능한 경우와 그 원리에 대한 설명입니다:  차원 수가 다른 경우:          broadcasting은 차원 수가 다르더라도 가능합니다. 누락된 차원은 크기가 1로 간주됩니다.        한 배열의 차원 크기가 다른 배열의 해당 차원 크기에 1이 있는 경우:          차원 크기가 1인 차원은 다른 배열의 해당 차원 크기에 맞춰 확장됩니다.      예를 들어, x 배열이 shape이 (2, 1, 2, 1)이고 y 배열이 shape이 (1, 4, 1, 1)인 경우, broadcasting이 가능합니다. 이 경우, x의 두 번째 차원과 y의 두 번째 차원이 크기 1에서 서로 맞춰져 확장됩니다. 따라서 x @ y에서 두 배열 간의 행렬 곱셈이 가능합니다.이런 방식으로 broadcasting이 작동하면서 두 배열 간의 연산이 가능하게 됩니다. NumPy는 이러한 broadcasting을 통해 편리하게 다양한 형태의 배열 간 연산을 수행할 수 있도록 지원합니다.예시두 5차원 배열 A와 B, 그리고 5차원 배열 C에 대한 행렬 곱셈을 예시로 들어보겠습니다. 각 배열의 차원과 크기를 명시하겠습니다.\\[D_{ijkln} = \\sum_{m} A_{ijmkl} \\cdot B_{mklno} \\cdot C_{opqnr}\\]여기서:  ( A )의 shape: (2, 3, 4, 5, 6)  ( B )의 shape: (3, 4, 2, 6, 1)  ( C )의 shape: (4, 2, 3, 1, 5)이제 곱셈을 수행하는 과정을 자세히 설명하겠습니다.과정  D의 첫 번째 차원 (i에 대한 차원):          ( A )의 첫 번째 차원과 ( B )의 첫 번째 차원 중 크기가 더 큰 값으로 결정합니다. 따라서 ( D )의 첫 번째 차원은 3입니다.        D의 두 번째 차원 (j에 대한 차원):          ( B )의 두 번째 차원이 그대로 사용됩니다. 따라서 ( D )의 두 번째 차원은 4입니다.        D의 세 번째 차원 (k에 대한 차원):          ( A )의 세 번째 차원과 ( C )의 첫 번째 차원 중 크기가 더 큰 값으로 결정합니다. 따라서 ( D )의 세 번째 차원은 4입니다.        D의 네 번째 차원 (l에 대한 차원):          ( A )의 네 번째 차원이 그대로 사용됩니다. 따라서 ( D )의 네 번째 차원은 5입니다.        D의 다섯 번째 차원 (n에 대한 차원):          ( C )의 다섯 번째 차원이 그대로 사용됩니다. 따라서 ( D )의 다섯 번째 차원은 5입니다.      결론따라서, ( D )의 shape은 (3, 4, 4, 5, 5)가 됩니다. 이제 ( D )의 각 원소를 구하는데 필요한 곱셈을 수행하여 최종 결과를 얻을 수 있습니다. 이 과정은 각 차원에 대해 대응하는 크기를 고려하여 수행됩니다.  아직도 100퍼센트 이해가 안된것같다…  해당 내용을 코드로 바꿔서 돌려보니 작동하지 않는다. chat gpt 3.5로 돌려서 지 멋대로 내용을 만들어 낸듯하다…제대로 알아내면 올릴 곳…해당 내용에 대해 더 찾아보고 수정해야겠다"
  },
  
  {
    "title": "Day13",
    "url": "/posts/Day13/",
    "categories": "BoostCamp, Week3",
    "tags": "data, visualization",
    "date": "2023-11-22 20:00:00 +0900",
    





    
    "snippet": "Data Viz  시각화의 요소들  Matplotlib  Bar plot  line plot  scatter plot멘토링  RecSys의 validation          offline validation                  top K, precision &amp; recall …                    online valid...",
    "content": "Data Viz  시각화의 요소들  Matplotlib  Bar plot  line plot  scatter plot멘토링  RecSys의 validation          offline validation                  top K, precision &amp; recall …                    online validation                  A/B test                      재노출의 설정          domain에 따라 class에 따라 후처리를 통해 빈도 설정                  우유는 1주일, 옷은 구매하면 x          상황마다 회사마다 다 다르다                    피어세션  기본과제 4 &amp; 5 리뷰"
  },
  
  {
    "title": "행렬 곱에서의 transpose",
    "url": "/posts/matmul_transpose/",
    "categories": "BoostCamp, 궁금증",
    "tags": "dl, transformer, score, T, transpose, permute",
    "date": "2023-11-21 20:00:00 +0900",
    





    
    "snippet": "transformer score 파트에서 생긴 의문들",
    "content": "transformer score 파트에서 생긴 의문들"
  },
  
  {
    "title": "Day12",
    "url": "/posts/Day12/",
    "categories": "BoostCamp, Week3",
    "tags": "dl",
    "date": "2023-11-21 20:00:00 +0900",
    





    
    "snippet": "TransformerGenerative Model과제 5  score 파트에서 생긴 의문          행렬 곱에서의 transpose      깃허브  post link  image upload          use cdn        sitemap 재지정  naver 서치어드바이저 등록",
    "content": "TransformerGenerative Model과제 5  score 파트에서 생긴 의문          행렬 곱에서의 transpose      깃허브  post link  image upload          use cdn        sitemap 재지정  naver 서치어드바이저 등록"
  },
  
  {
    "title": "Transfer Learning에서의 의문",
    "url": "/posts/transfer_learning/",
    "categories": "BoostCamp, 궁금증",
    "tags": "dl, transfer, transfer learning",
    "date": "2023-11-20 20:00:00 +0900",
    





    
    "snippet": "transfer learning의 layer 수정 이유",
    "content": "transfer learning의 layer 수정 이유"
  },
  
  {
    "title": "Day11",
    "url": "/posts/Day11/",
    "categories": "BoostCamp, Week3",
    "tags": "dl",
    "date": "2023-11-20 20:00:00 +0900",
    





    
    "snippet": "DL Historical reviewNN &amp; MLPOptimization  Generalization  Under-fitting vs Over-fitting  Cross Validation  Bias-Variance tradeoff  Bootstrapping  Bagging &amp; BoostingCNNRNN  RNN  LSTM  GRU피어세...",
    "content": "DL Historical reviewNN &amp; MLPOptimization  Generalization  Under-fitting vs Over-fitting  Cross Validation  Bias-Variance tradeoff  Bootstrapping  Bagging &amp; BoostingCNNRNN  RNN  LSTM  GRU피어세션  심화과제1 리뷰  transfer learning에서 layer를 왜 그렇게 수정했는지          transfer learning      과제 1~4  MLP, Optimization, CNN, LSTM"
  },
  
  {
    "title": "Day10",
    "url": "/posts/Day10/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-17 20:00:00 +0900",
    





    
    "snippet": "심화 과제 1  계속 시도 중… 이지만 어렵다스페셜 피어세션  새로운분들을 만나고 관심사에 대해 알아보는 시간피어세션  스페셜 피어세션에 대한 이야기  팀 주간 학습회고주간 학습 회고  이번 주는 생각보다 처음 경험하는 내용도 많았고 배운것도 많은 것 같다.  특히 gather, forward, backward, hook, apply는 처음 배운 내용...",
    "content": "심화 과제 1  계속 시도 중… 이지만 어렵다스페셜 피어세션  새로운분들을 만나고 관심사에 대해 알아보는 시간피어세션  스페셜 피어세션에 대한 이야기  팀 주간 학습회고주간 학습 회고  이번 주는 생각보다 처음 경험하는 내용도 많았고 배운것도 많은 것 같다.  특히 gather, forward, backward, hook, apply는 처음 배운 내용들이라 체득하는데 오래 걸린 것 같다.깃 블로그 업데이트  jeykll theme에서 toc를 써보고 싶은데 계속 안되서 고민중…          Heading을 # 하나가 아니라 ## 부터 toc 정상 적용!      "
  },
  
  {
    "title": "Day9",
    "url": "/posts/Day9/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-16 20:00:00 +0900",
    





    
    "snippet": "Multi GPU  Single Node Single GPU  Single Node Multi GPU  Multi Node Multi GPU  Model Parallel  Data Parallel          Data Parallel      DistributedData Parallel      Hyperparameter Tuning  Hyperp...",
    "content": "Multi GPU  Single Node Single GPU  Single Node Multi GPU  Multi Node Multi GPU  Model Parallel  Data Parallel          Data Parallel      DistributedData Parallel      Hyperparameter Tuning  Hyperparameter Tuning(마지막에 쥐어짤 때)          Grid Layout      Random Layout      Bayesian Layout(최근)        Ray          Multi Node Multi GPU 지원      PyTorch Troubleshooting  OOM(Out of Memory)          Batch Size ↓ → GPU clean → Run      torch.cuda.empty_cache()      del      tensor to list      inference → torch.no_grad()                  backward pass에서의 메모리에서 자유로움                    기본 과제 2 마무리피어세션  기본 과제 2 리뷰마스터클래스  최성철 마스터님의 &lt;ChatGPT시대&gt;  ChatGPT 많이 활용하기"
  },
  
  {
    "title": "Day8",
    "url": "/posts/Day8/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-15 20:00:00 +0900",
    





    
    "snippet": "PyTorch 모델 불러오기  save  checkpoint  transfer learningMonitoring tools  Tensorboard  Wandb기본 과제 2멘토링  논문 읽는 법에 대하여피어세션  기본 과제 1 리뷰두런두런 1회차  변성윤 마스터님 &lt;어쩌다 데이터 사이언티스트&gt;  나는 나 자신을 얼마나 알고 있는가?",
    "content": "PyTorch 모델 불러오기  save  checkpoint  transfer learningMonitoring tools  Tensorboard  Wandb기본 과제 2멘토링  논문 읽는 법에 대하여피어세션  기본 과제 1 리뷰두런두런 1회차  변성윤 마스터님 &lt;어쩌다 데이터 사이언티스트&gt;  나는 나 자신을 얼마나 알고 있는가?"
  },
  
  {
    "title": "Day7",
    "url": "/posts/Day7/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-14 20:00:00 +0900",
    





    
    "snippet": "Pytorch AutoGrad &amp; Optimizer  nn.Module  nn.Parameter  forward  backwardPyTorch Dataset &amp; DataLoader  transforms / Dataset / DataLoader 모듈피어세션  기본 과제 1 (~nn.Module 알쓸신접 전까지) 리뷰기본 과제 1 마무리",
    "content": "Pytorch AutoGrad &amp; Optimizer  nn.Module  nn.Parameter  forward  backwardPyTorch Dataset &amp; DataLoader  transforms / Dataset / DataLoader 모듈피어세션  기본 과제 1 (~nn.Module 알쓸신접 전까지) 리뷰기본 과제 1 마무리"
  },
  
  {
    "title": "Day6",
    "url": "/posts/Day6/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-13 20:00:00 +0900",
    





    
    "snippet": "PyTorch  basic  구조 이해피어세션  심화과제 1 &amp; 2 &amp; 3  기본 과제 1 (nn.Module 알쓸신잡 전까지)기본 과제 1  상당히 오래걸렸지만 새로 알아가는 것이 많았다.",
    "content": "PyTorch  basic  구조 이해피어세션  심화과제 1 &amp; 2 &amp; 3  기본 과제 1 (nn.Module 알쓸신잡 전까지)기본 과제 1  상당히 오래걸렸지만 새로 알아가는 것이 많았다."
  },
  
  {
    "title": "Day5",
    "url": "/posts/Day5/",
    "categories": "BoostCamp, Week1",
    "tags": "ai math",
    "date": "2023-11-10 15:00:00 +0900",
    





    
    "snippet": "심화 과제 1  경사하강법에 대해 좀 더 깊게 알아가는 시간깃블로그 업데이트  아직 미숙한 관계로 더 공부 후에 업데이트 해야겠다…주간 학습 회고  첫주차는 알았던 내용의 복습 &amp; 놓치고 있던 몇몇 부분을 찾는 시간이었다  주말에는 휴식을 가지면서 부족한 부분과 github.io에 대해 좀 더 공부해 봐야겠다",
    "content": "심화 과제 1  경사하강법에 대해 좀 더 깊게 알아가는 시간깃블로그 업데이트  아직 미숙한 관계로 더 공부 후에 업데이트 해야겠다…주간 학습 회고  첫주차는 알았던 내용의 복습 &amp; 놓치고 있던 몇몇 부분을 찾는 시간이었다  주말에는 휴식을 가지면서 부족한 부분과 github.io에 대해 좀 더 공부해 봐야겠다"
  },
  
  {
    "title": "Day4",
    "url": "/posts/Day4/",
    "categories": "BoostCamp, Week1",
    "tags": "ai math",
    "date": "2023-11-09 20:00:00 +0900",
    





    
    "snippet": "경사하강법  미분 / gradient vector  gradient descent / stochastic gradient descent(minibatch)    딥러닝    softmax(classification)  activation function  multi-layer perceptron  backprogpagation(chian rule)확률...",
    "content": "경사하강법  미분 / gradient vector  gradient descent / stochastic gradient descent(minibatch)    딥러닝    softmax(classification)  activation function  multi-layer perceptron  backprogpagation(chian rule)확률론  discrete(이산형) / continuous(연속형)  조건부확률  몬테카를로 샘플링(확률 분포를 모를 때)통계학  MLE / Log-likelihood          쿨백-라이블러 발산(KL Divergence)        베이즈 정리  precision / recallCNN  convolution 연산 / convolution 연산의 역전파RNN  시퀀스 데이터  vanishing gradient -&gt; GRU / LSTM피어세션  1 주차 학습내용 리뷰  과제 1 &amp; 2 &amp; 3 리뷰마스터클래스  임성빈 마스터님의 &lt;AI &amp; Math FAQ&gt;  AI를 배우는 사람에게 황금같은 조언"
  },
  
  {
    "title": "Day3",
    "url": "/posts/Day3/",
    "categories": "BoostCamp, Week1",
    "tags": "python, ai math",
    "date": "2023-11-08 20:00:00 +0900",
    





    
    "snippet": "Python Data Handling  csv / html / xml / json넘파이판다스  series / dataframe  lambda / map / apply  pandas built-in functions  groupby / crosstab / merge / concat  persistence벡터  basic operation  Norm  ...",
    "content": "Python Data Handling  csv / html / xml / json넘파이판다스  series / dataframe  lambda / map / apply  pandas built-in functions  groupby / crosstab / merge / concat  persistence벡터  basic operation  Norm  inner product행렬  basic operation  inner product  inv / pinv          연립방정식 / linear regression      기본 과제 2 &amp; 3피어세션  데이터 전처리 (Filtering &amp; Sorting) 리뷰  새로 오신 팀원분과 자기소개과제 및 퀴즈 리마인드"
  },
  
  {
    "title": "Day2",
    "url": "/posts/Day2/",
    "categories": "BoostCamp, Week1",
    "tags": "python",
    "date": "2023-11-07 20:00:00 +0900",
    





    
    "snippet": "파이썬 데이터 구조파이썬 코드  python style code          ex) split &amp; join, list comprehension…      파이썬 객체지향 프로그래밍  Class          Inheritance / Polymorphism / Visibility        decorator모듈 / 프로젝트  import ...",
    "content": "파이썬 데이터 구조파이썬 코드  python style code          ex) split &amp; join, list comprehension…      파이썬 객체지향 프로그래밍  Class          Inheritance / Polymorphism / Visibility        decorator모듈 / 프로젝트  import / namespace  Virtual Environment파일 / 예외 처리 / 로그  configparser / argparser기본 과제 1피어세션  데이터 전처리 (Getting &amp; Knowing) 리뷰  팀 그라운드 룰 설정데이터 전처리  Filtering &amp; Sorting"
  },
  
  {
    "title": "Day1",
    "url": "/posts/Day1/",
    "categories": "BoostCamp, Week1",
    "tags": "python",
    "date": "2023-11-06 20:00:00 +0900",
    





    
    "snippet": "파이썬 개발환경 설정  vscode / anaconda / terminal 등파이썬 기초 문법  variable / function / conditional &amp; loop / string피어세션  자기소개  Datamanim 사이트 이용 -&gt; 전처리 관련 학습 계획데이터 전처리  Getting &amp; Knowing깃블로그 생성  them...",
    "content": "파이썬 개발환경 설정  vscode / anaconda / terminal 등파이썬 기초 문법  variable / function / conditional &amp; loop / string피어세션  자기소개  Datamanim 사이트 이용 -&gt; 전처리 관련 학습 계획데이터 전처리  Getting &amp; Knowing깃블로그 생성  theme / google search console / google ad sense"
  }
  
]

