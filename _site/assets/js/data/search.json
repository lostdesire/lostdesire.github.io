[
  
  {
    "title": "Matrix Multiply",
    "url": "/posts/Matrix_Multiply/",
    "categories": "BoostCamp, 궁금증",
    "tags": "numpy, matmul",
    "date": "2023-11-22 20:00:00 +0900",
    





    
    "snippet": "다차원에서의 행렬곱  행렬 곱에 대해서 고민하며 시도해보다가 (2, 1, 2, 3, 5)와 (1, 4, 1, 3, 5)가 곱해진다는 것을 알고 혼란에 빠져 버렸다.  이를 해결하기 위해 chat gpt에게 물어본 결과다.BroadcastingNumPy에서는 서로 다른 크기의 배열 간에도 행렬 연산을 수행할 수 있는 기능인 broadcasting이 제공...",
    "content": "다차원에서의 행렬곱  행렬 곱에 대해서 고민하며 시도해보다가 (2, 1, 2, 3, 5)와 (1, 4, 1, 3, 5)가 곱해진다는 것을 알고 혼란에 빠져 버렸다.  이를 해결하기 위해 chat gpt에게 물어본 결과다.BroadcastingNumPy에서는 서로 다른 크기의 배열 간에도 행렬 연산을 수행할 수 있는 기능인 broadcasting이 제공됩니다. Broadcasting은 배열의 차원을 자동으로 조정하여 연산이 가능하도록 만듭니다. 특히, 크기가 1인 차원을 다른 배열의 차원에 맞춰 확장시키는 것이 주요한 원리입니다.다음은 broadcasting이 가능한 경우와 그 원리에 대한 설명입니다:  차원 수가 다른 경우:          broadcasting은 차원 수가 다르더라도 가능합니다. 누락된 차원은 크기가 1로 간주됩니다.        한 배열의 차원 크기가 다른 배열의 해당 차원 크기에 1이 있는 경우:          차원 크기가 1인 차원은 다른 배열의 해당 차원 크기에 맞춰 확장됩니다.      예를 들어, x 배열이 shape이 (2, 1, 2, 1)이고 y 배열이 shape이 (1, 4, 1, 1)인 경우, broadcasting이 가능합니다. 이 경우, x의 두 번째 차원과 y의 두 번째 차원이 크기 1에서 서로 맞춰져 확장됩니다. 따라서 x @ y에서 두 배열 간의 행렬 곱셈이 가능합니다.이런 방식으로 broadcasting이 작동하면서 두 배열 간의 연산이 가능하게 됩니다. NumPy는 이러한 broadcasting을 통해 편리하게 다양한 형태의 배열 간 연산을 수행할 수 있도록 지원합니다.예시두 5차원 배열 A와 B, 그리고 5차원 배열 C에 대한 행렬 곱셈을 예시로 들어보겠습니다. 각 배열의 차원과 크기를 명시하겠습니다.\\[D_{ijkln} = \\sum_{m} A_{ijmkl} \\cdot B_{mklno} \\cdot C_{opqnr}\\]여기서:  ( A )의 shape: (2, 3, 4, 5, 6)  ( B )의 shape: (3, 4, 2, 6, 1)  ( C )의 shape: (4, 2, 3, 1, 5)이제 곱셈을 수행하는 과정을 자세히 설명하겠습니다.과정  D의 첫 번째 차원 (i에 대한 차원):          ( A )의 첫 번째 차원과 ( B )의 첫 번째 차원 중 크기가 더 큰 값으로 결정합니다. 따라서 ( D )의 첫 번째 차원은 3입니다.        D의 두 번째 차원 (j에 대한 차원):          ( B )의 두 번째 차원이 그대로 사용됩니다. 따라서 ( D )의 두 번째 차원은 4입니다.        D의 세 번째 차원 (k에 대한 차원):          ( A )의 세 번째 차원과 ( C )의 첫 번째 차원 중 크기가 더 큰 값으로 결정합니다. 따라서 ( D )의 세 번째 차원은 4입니다.        D의 네 번째 차원 (l에 대한 차원):          ( A )의 네 번째 차원이 그대로 사용됩니다. 따라서 ( D )의 네 번째 차원은 5입니다.        D의 다섯 번째 차원 (n에 대한 차원):          ( C )의 다섯 번째 차원이 그대로 사용됩니다. 따라서 ( D )의 다섯 번째 차원은 5입니다.      결론따라서, ( D )의 shape은 (3, 4, 4, 5, 5)가 됩니다. 이제 ( D )의 각 원소를 구하는데 필요한 곱셈을 수행하여 최종 결과를 얻을 수 있습니다. 이 과정은 각 차원에 대해 대응하는 크기를 고려하여 수행됩니다.  아직도 100퍼센트 이해가 안된것같다…"
  },
  
  {
    "title": "Day13",
    "url": "/posts/Day13/",
    "categories": "BoostCamp, Week3",
    "tags": "data, visualization",
    "date": "2023-11-22 20:00:00 +0900",
    





    
    "snippet": "Data Viz  시각화의 요소들  Matplotlib  Bar plot  line plot  scatter plot멘토링  RecSys의 validation          offline validation                  top K, precision &amp; recall …                    online valid...",
    "content": "Data Viz  시각화의 요소들  Matplotlib  Bar plot  line plot  scatter plot멘토링  RecSys의 validation          offline validation                  top K, precision &amp; recall …                    online validation                  A/B test                      재노출의 설정          domain에 따라 class에 따라 후처리를 통해 빈도 설정                  우유는 1주일, 옷은 구매하면 x          상황마다 회사마다 다 다르다                    피어세션  기본과제 4 &amp; 5 리뷰"
  },
  
  {
    "title": "행렬 곱에서의 transpose",
    "url": "/posts/matmul_transpose/",
    "categories": "BoostCamp, 궁금증",
    "tags": "dl, transformer, score, T, transpose, permute",
    "date": "2023-11-21 20:00:00 +0900",
    





    
    "snippet": "transformer score 파트에서 생긴 의문들",
    "content": "transformer score 파트에서 생긴 의문들"
  },
  
  {
    "title": "Day12",
    "url": "/posts/Day12/",
    "categories": "BoostCamp, Week3",
    "tags": "dl",
    "date": "2023-11-21 20:00:00 +0900",
    





    
    "snippet": "TransformerGenerative Model과제 5  score 파트에서 생긴 의문          행렬 곱에서의 transpose      깃허브  post link  image upload          use cdn        sitemap 재지정  naver 서치어드바이저 등록",
    "content": "TransformerGenerative Model과제 5  score 파트에서 생긴 의문          행렬 곱에서의 transpose      깃허브  post link  image upload          use cdn        sitemap 재지정  naver 서치어드바이저 등록"
  },
  
  {
    "title": "Transfer Learning에서의 의문",
    "url": "/posts/transfer_learning/",
    "categories": "BoostCamp, 궁금증",
    "tags": "dl, transfer, transfer learning",
    "date": "2023-11-20 20:00:00 +0900",
    





    
    "snippet": "transfer learning의 layer 수정 이유",
    "content": "transfer learning의 layer 수정 이유"
  },
  
  {
    "title": "Day11",
    "url": "/posts/Day11/",
    "categories": "BoostCamp, Week3",
    "tags": "dl",
    "date": "2023-11-20 20:00:00 +0900",
    





    
    "snippet": "DL Historical reviewNN &amp; MLPOptimization  Generalization  Under-fitting vs Over-fitting  Cross Validation  Bias-Variance tradeoff  Bootstrapping  Bagging &amp; BoostingCNNRNN  RNN  LSTM  GRU피어세...",
    "content": "DL Historical reviewNN &amp; MLPOptimization  Generalization  Under-fitting vs Over-fitting  Cross Validation  Bias-Variance tradeoff  Bootstrapping  Bagging &amp; BoostingCNNRNN  RNN  LSTM  GRU피어세션  심화과제1 리뷰  transfer learning에서 layer를 왜 그렇게 수정했는지          transfer learning      과제 1~4  MLP, Optimization, CNN, LSTM"
  },
  
  {
    "title": "Day10",
    "url": "/posts/Day10/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-17 20:00:00 +0900",
    





    
    "snippet": "심화 과제 1  계속 시도 중… 이지만 어렵다스페셜 피어세션  새로운분들을 만나고 관심사에 대해 알아보는 시간피어세션  스페셜 피어세션에 대한 이야기  팀 주간 학습회고주간 학습 회고  이번 주는 생각보다 처음 경험하는 내용도 많았고 배운것도 많은 것 같다.  특히 gather, forward, backward, hook, apply는 처음 배운 내용...",
    "content": "심화 과제 1  계속 시도 중… 이지만 어렵다스페셜 피어세션  새로운분들을 만나고 관심사에 대해 알아보는 시간피어세션  스페셜 피어세션에 대한 이야기  팀 주간 학습회고주간 학습 회고  이번 주는 생각보다 처음 경험하는 내용도 많았고 배운것도 많은 것 같다.  특히 gather, forward, backward, hook, apply는 처음 배운 내용들이라 체득하는데 오래 걸린 것 같다.깃 블로그 업데이트  jeykll theme에서 toc를 써보고 싶은데 계속 안되서 고민중…          Heading을 # 하나가 아니라 ## 부터 toc 정상 적용!      "
  },
  
  {
    "title": "Day9",
    "url": "/posts/Day9/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-16 20:00:00 +0900",
    





    
    "snippet": "Multi GPU  Single Node Single GPU  Single Node Multi GPU  Multi Node Multi GPU  Model Parallel  Data Parallel          Data Parallel      DistributedData Parallel      Hyperparameter Tuning  Hyperp...",
    "content": "Multi GPU  Single Node Single GPU  Single Node Multi GPU  Multi Node Multi GPU  Model Parallel  Data Parallel          Data Parallel      DistributedData Parallel      Hyperparameter Tuning  Hyperparameter Tuning(마지막에 쥐어짤 때)          Grid Layout      Random Layout      Bayesian Layout(최근)        Ray          Multi Node Multi GPU 지원      PyTorch Troubleshooting  OOM(Out of Memory)          Batch Size ↓ → GPU clean → Run      torch.cuda.empty_cache()      del      tensor to list      inference → torch.no_grad()                  backward pass에서의 메모리에서 자유로움                    기본 과제 2 마무리피어세션  기본 과제 2 리뷰마스터클래스  최성철 마스터님의   ChatGPT 많이 활용하기"
  },
  
  {
    "title": "Day8",
    "url": "/posts/Day8/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-15 20:00:00 +0900",
    





    
    "snippet": "PyTorch 모델 불러오기  save  checkpoint  transfer learningMonitoring tools  Tensorboard  Wandb기본 과제 2멘토링  논문 읽는 법에 대하여피어세션  기본 과제 1 리뷰두런두런 1회차  변성윤 마스터님   나는 나 자신을 얼마나 알고 있는가?",
    "content": "PyTorch 모델 불러오기  save  checkpoint  transfer learningMonitoring tools  Tensorboard  Wandb기본 과제 2멘토링  논문 읽는 법에 대하여피어세션  기본 과제 1 리뷰두런두런 1회차  변성윤 마스터님   나는 나 자신을 얼마나 알고 있는가?"
  },
  
  {
    "title": "Day7",
    "url": "/posts/Day7/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-14 20:00:00 +0900",
    





    
    "snippet": "Pytorch AutoGrad &amp; Optimizer  nn.Module  nn.Parameter  forward  backwardPyTorch Dataset &amp; DataLoader  transforms / Dataset / DataLoader 모듈피어세션  기본 과제 1 (~nn.Module 알쓸신접 전까지) 리뷰기본 과제 1 마무리",
    "content": "Pytorch AutoGrad &amp; Optimizer  nn.Module  nn.Parameter  forward  backwardPyTorch Dataset &amp; DataLoader  transforms / Dataset / DataLoader 모듈피어세션  기본 과제 1 (~nn.Module 알쓸신접 전까지) 리뷰기본 과제 1 마무리"
  },
  
  {
    "title": "Day6",
    "url": "/posts/Day6/",
    "categories": "BoostCamp, Week2",
    "tags": "pytorch",
    "date": "2023-11-13 20:00:00 +0900",
    





    
    "snippet": "PyTorch  basic  구조 이해피어세션  심화과제 1 &amp; 2 &amp; 3  기본 과제 1 (nn.Module 알쓸신잡 전까지)기본 과제 1  상당히 오래걸렸지만 새로 알아가는 것이 많았다.",
    "content": "PyTorch  basic  구조 이해피어세션  심화과제 1 &amp; 2 &amp; 3  기본 과제 1 (nn.Module 알쓸신잡 전까지)기본 과제 1  상당히 오래걸렸지만 새로 알아가는 것이 많았다."
  },
  
  {
    "title": "Day5",
    "url": "/posts/Day5/",
    "categories": "BoostCamp, Week1",
    "tags": "ai math",
    "date": "2023-11-10 15:00:00 +0900",
    





    
    "snippet": "심화 과제 1  경사하강법에 대해 좀 더 깊게 알아가는 시간깃블로그 업데이트  아직 미숙한 관계로 더 공부 후에 업데이트 해야겠다…주간 학습 회고  첫주차는 알았던 내용의 복습 &amp; 놓치고 있던 몇몇 부분을 찾는 시간이었다  주말에는 휴식을 가지면서 부족한 부분과 github.io에 대해 좀 더 공부해 봐야겠다",
    "content": "심화 과제 1  경사하강법에 대해 좀 더 깊게 알아가는 시간깃블로그 업데이트  아직 미숙한 관계로 더 공부 후에 업데이트 해야겠다…주간 학습 회고  첫주차는 알았던 내용의 복습 &amp; 놓치고 있던 몇몇 부분을 찾는 시간이었다  주말에는 휴식을 가지면서 부족한 부분과 github.io에 대해 좀 더 공부해 봐야겠다"
  },
  
  {
    "title": "Day4",
    "url": "/posts/Day4/",
    "categories": "BoostCamp, Week1",
    "tags": "ai math",
    "date": "2023-11-09 20:00:00 +0900",
    





    
    "snippet": "경사하강법  미분 / gradient vector  gradient descent / stochastic gradient descent(minibatch)    딥러닝    softmax(classification)  activation function  multi-layer perceptron  backprogpagation(chian rule)확률...",
    "content": "경사하강법  미분 / gradient vector  gradient descent / stochastic gradient descent(minibatch)    딥러닝    softmax(classification)  activation function  multi-layer perceptron  backprogpagation(chian rule)확률론  discrete(이산형) / continuous(연속형)  조건부확률  몬테카를로 샘플링(확률 분포를 모를 때)통계학  MLE / Log-likelihood          쿨백-라이블러 발산(KL Divergence)        베이즈 정리  precision / recallCNN  convolution 연산 / convolution 연산의 역전파RNN  시퀀스 데이터  vanishing gradient -&gt; GRU / LSTM피어세션  1 주차 학습내용 리뷰  과제 1 &amp; 2 &amp; 3 리뷰마스터클래스  임성빈 마스터님 &lt;AI &amp; Math FAQ&gt;  AI를 배우는 사람에게 황금같은 조언"
  },
  
  {
    "title": "Day3",
    "url": "/posts/Day3/",
    "categories": "BoostCamp, Week1",
    "tags": "python, ai math",
    "date": "2023-11-08 20:00:00 +0900",
    





    
    "snippet": "Python Data Handling  csv / html / xml / json넘파이판다스  series / dataframe  lambda / map / apply  pandas built-in functions  groupby / crosstab / merge / concat  persistence벡터  basic operation  Norm  ...",
    "content": "Python Data Handling  csv / html / xml / json넘파이판다스  series / dataframe  lambda / map / apply  pandas built-in functions  groupby / crosstab / merge / concat  persistence벡터  basic operation  Norm  inner product행렬  basic operation  inner product  inv / pinv          연립방정식 / linear regression      기본 과제 2 &amp; 3피어세션  데이터 전처리 (Filtering &amp; Sorting) 리뷰  새로 오신 팀원분과 자기소개과제 및 퀴즈 리마인드"
  },
  
  {
    "title": "Day2",
    "url": "/posts/Day2/",
    "categories": "BoostCamp, Week1",
    "tags": "python",
    "date": "2023-11-07 20:00:00 +0900",
    





    
    "snippet": "파이썬 데이터 구조파이썬 코드  python style code          ex) split &amp; join, list comprehension…      파이썬 객체지향 프로그래밍  Class          Inheritance / Polymorphism / Visibility        decorator모듈 / 프로젝트  import ...",
    "content": "파이썬 데이터 구조파이썬 코드  python style code          ex) split &amp; join, list comprehension…      파이썬 객체지향 프로그래밍  Class          Inheritance / Polymorphism / Visibility        decorator모듈 / 프로젝트  import / namespace  Virtual Environment파일 / 예외 처리 / 로그  configparser / argparser기본 과제 1피어세션  데이터 전처리 (Getting &amp; Knowing) 리뷰  팀 그라운드 룰 설정데이터 전처리  Filtering &amp; Sorting"
  },
  
  {
    "title": "Day1",
    "url": "/posts/Day1/",
    "categories": "BoostCamp, Week1",
    "tags": "python",
    "date": "2023-11-06 20:00:00 +0900",
    





    
    "snippet": "파이썬 개발환경 설정  vscode / anaconda / terminal 등파이썬 기초 문법  variable / function / conditional &amp; loop / string피어세션  자기소개  Datamanim 사이트 이용 -&gt; 전처리 관련 학습 계획데이터 전처리  Getting &amp; Knowing깃블로그 생성  them...",
    "content": "파이썬 개발환경 설정  vscode / anaconda / terminal 등파이썬 기초 문법  variable / function / conditional &amp; loop / string피어세션  자기소개  Datamanim 사이트 이용 -&gt; 전처리 관련 학습 계획데이터 전처리  Getting &amp; Knowing깃블로그 생성  theme / google search console / google ad sense"
  }
  
]

